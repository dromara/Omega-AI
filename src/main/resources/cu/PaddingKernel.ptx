//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31833905
// Cuda compilation tools, release 11.8, V11.8.89
// Based on NVVM 7.0.1
//

.version 7.8
.target sm_52
.address_size 64

	// .globl	constPadding2d

.visible .entry constPadding2d(
	.param .u64 constPadding2d_param_0,
	.param .u64 constPadding2d_param_1,
	.param .u64 constPadding2d_param_2,
	.param .u64 constPadding2d_param_3,
	.param .u64 constPadding2d_param_4,
	.param .u64 constPadding2d_param_5,
	.param .u64 constPadding2d_param_6,
	.param .u64 constPadding2d_param_7,
	.param .u64 constPadding2d_param_8,
	.param .u64 constPadding2d_param_9,
	.param .u64 constPadding2d_param_10,
	.param .u64 constPadding2d_param_11,
	.param .f32 constPadding2d_param_12,
	.param .u64 constPadding2d_param_13
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<56>;


	ld.param.u64 	%rd20, [constPadding2d_param_0];
	ld.param.u64 	%rd21, [constPadding2d_param_1];
	ld.param.u64 	%rd22, [constPadding2d_param_4];
	ld.param.u64 	%rd23, [constPadding2d_param_5];
	ld.param.u64 	%rd24, [constPadding2d_param_6];
	ld.param.u64 	%rd25, [constPadding2d_param_7];
	ld.param.u64 	%rd26, [constPadding2d_param_8];
	ld.param.u64 	%rd27, [constPadding2d_param_9];
	ld.param.u64 	%rd28, [constPadding2d_param_10];
	ld.param.u64 	%rd29, [constPadding2d_param_11];
	ld.param.f32 	%f3, [constPadding2d_param_12];
	ld.param.u64 	%rd30, [constPadding2d_param_13];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd51, %r4;
	setp.ge.u64 	%p1, %rd51, %rd20;
	@%p1 bra 	$L__BB0_14;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd30;
	cvt.u32.u64 	%r7, %rd26;
	cvt.u32.u64 	%r12, %rd25;

$L__BB0_2:
	or.b64  	%rd31, %rd51, %rd26;
	and.b64  	%rd32, %rd31, -4294967296;
	setp.eq.s64 	%p2, %rd32, 0;
	@%p2 bra 	$L__BB0_4;

	div.u64 	%rd52, %rd51, %rd26;
	mul.lo.s64 	%rd33, %rd52, %rd26;
	sub.s64 	%rd53, %rd51, %rd33;
	bra.uni 	$L__BB0_5;

$L__BB0_4:
	cvt.u32.u64 	%r8, %rd51;
	div.u32 	%r9, %r8, %r7;
	mul.lo.s32 	%r10, %r9, %r7;
	sub.s32 	%r11, %r8, %r10;
	cvt.u64.u32 	%rd52, %r9;
	cvt.u64.u32 	%rd53, %r11;

$L__BB0_5:
	or.b64  	%rd34, %rd52, %rd25;
	and.b64  	%rd35, %rd34, -4294967296;
	setp.eq.s64 	%p3, %rd35, 0;
	@%p3 bra 	$L__BB0_7;

	rem.u64 	%rd54, %rd52, %rd25;
	bra.uni 	$L__BB0_8;

$L__BB0_7:
	cvt.u32.u64 	%r13, %rd52;
	rem.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd54, %r14;

$L__BB0_8:
	cvt.s64.s32 	%rd36, %rd54;
	setp.lt.s64 	%p4, %rd36, %rd28;
	cvt.s64.s32 	%rd37, %rd53;
	setp.lt.s64 	%p5, %rd37, %rd29;
	or.pred  	%p6, %p4, %p5;
	sub.s64 	%rd15, %rd36, %rd28;
	setp.ge.s64 	%p7, %rd15, %rd22;
	or.pred  	%p8, %p7, %p6;
	sub.s64 	%rd38, %rd37, %rd29;
	setp.ge.s64 	%p9, %rd38, %rd23;
	or.pred  	%p10, %p9, %p8;
	mov.f32 	%f4, %f3;
	@%p10 bra 	$L__BB0_13;

	or.b64  	%rd39, %rd51, %rd27;
	and.b64  	%rd40, %rd39, -4294967296;
	setp.eq.s64 	%p11, %rd40, 0;
	@%p11 bra 	$L__BB0_11;

	div.u64 	%rd55, %rd51, %rd27;
	bra.uni 	$L__BB0_12;

$L__BB0_11:
	cvt.u32.u64 	%r15, %rd27;
	cvt.u32.u64 	%r16, %rd51;
	div.u32 	%r17, %r16, %r15;
	cvt.u64.u32 	%rd55, %r17;

$L__BB0_12:
	mul.lo.s64 	%rd41, %rd55, %rd24;
	sub.s64 	%rd42, %rd53, %rd29;
	mul.lo.s64 	%rd43, %rd15, %rd23;
	add.s64 	%rd44, %rd42, %rd43;
	add.s64 	%rd45, %rd44, %rd41;
	shl.b64 	%rd46, %rd45, 32;
	shr.s64 	%rd47, %rd46, 30;
	add.s64 	%rd48, %rd3, %rd47;
	ld.global.f32 	%f4, [%rd48];

$L__BB0_13:
	shl.b64 	%rd49, %rd51, 2;
	add.s64 	%rd50, %rd4, %rd49;
	st.global.f32 	[%rd50], %f4;
	add.s64 	%rd51, %rd51, %rd2;
	setp.lt.u64 	%p12, %rd51, %rd20;
	@%p12 bra 	$L__BB0_2;

$L__BB0_14:
	ret;

}
	// .globl	ConstantPadGrad2d
.visible .entry ConstantPadGrad2d(
	.param .u64 ConstantPadGrad2d_param_0,
	.param .u64 ConstantPadGrad2d_param_1,
	.param .u64 ConstantPadGrad2d_param_2,
	.param .u64 ConstantPadGrad2d_param_3,
	.param .u64 ConstantPadGrad2d_param_4,
	.param .u64 ConstantPadGrad2d_param_5,
	.param .u64 ConstantPadGrad2d_param_6,
	.param .u64 ConstantPadGrad2d_param_7,
	.param .u64 ConstantPadGrad2d_param_8,
	.param .u64 ConstantPadGrad2d_param_9,
	.param .u64 ConstantPadGrad2d_param_10,
	.param .u64 ConstantPadGrad2d_param_11,
	.param .u64 ConstantPadGrad2d_param_12
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<52>;


	ld.param.u64 	%rd19, [ConstantPadGrad2d_param_0];
	ld.param.u64 	%rd20, [ConstantPadGrad2d_param_1];
	ld.param.u64 	%rd21, [ConstantPadGrad2d_param_4];
	ld.param.u64 	%rd22, [ConstantPadGrad2d_param_5];
	ld.param.u64 	%rd23, [ConstantPadGrad2d_param_6];
	ld.param.u64 	%rd24, [ConstantPadGrad2d_param_8];
	ld.param.u64 	%rd25, [ConstantPadGrad2d_param_9];
	ld.param.u64 	%rd26, [ConstantPadGrad2d_param_10];
	ld.param.u64 	%rd27, [ConstantPadGrad2d_param_11];
	ld.param.u64 	%rd28, [ConstantPadGrad2d_param_12];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd47, %r4;
	setp.ge.u64 	%p1, %rd47, %rd19;
	@%p1 bra 	$L__BB1_12;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd28;
	cvt.u32.u64 	%r7, %rd23;
	cvt.u32.u64 	%r10, %rd22;
	cvt.u32.u64 	%r15, %rd21;

$L__BB1_2:
	or.b64  	%rd29, %rd47, %rd23;
	and.b64  	%rd30, %rd29, -4294967296;
	setp.eq.s64 	%p2, %rd30, 0;
	@%p2 bra 	$L__BB1_4;

	div.u64 	%rd48, %rd47, %rd23;
	bra.uni 	$L__BB1_5;

$L__BB1_4:
	cvt.u32.u64 	%r8, %rd47;
	div.u32 	%r9, %r8, %r7;
	cvt.u64.u32 	%rd48, %r9;

$L__BB1_5:
	or.b64  	%rd31, %rd47, %rd22;
	and.b64  	%rd32, %rd31, -4294967296;
	setp.eq.s64 	%p3, %rd32, 0;
	@%p3 bra 	$L__BB1_7;

	div.u64 	%rd49, %rd47, %rd22;
	mul.lo.s64 	%rd33, %rd49, %rd22;
	sub.s64 	%rd50, %rd47, %rd33;
	bra.uni 	$L__BB1_8;

$L__BB1_7:
	cvt.u32.u64 	%r11, %rd47;
	div.u32 	%r12, %r11, %r10;
	mul.lo.s32 	%r13, %r12, %r10;
	sub.s32 	%r14, %r11, %r13;
	cvt.u64.u32 	%rd49, %r12;
	cvt.u64.u32 	%rd50, %r14;

$L__BB1_8:
	or.b64  	%rd34, %rd49, %rd21;
	and.b64  	%rd35, %rd34, -4294967296;
	setp.eq.s64 	%p4, %rd35, 0;
	@%p4 bra 	$L__BB1_10;

	rem.u64 	%rd51, %rd49, %rd21;
	bra.uni 	$L__BB1_11;

$L__BB1_10:
	cvt.u32.u64 	%r16, %rd49;
	rem.u32 	%r17, %r16, %r15;
	cvt.u64.u32 	%rd51, %r17;

$L__BB1_11:
	mul.lo.s64 	%rd36, %rd48, %rd25;
	add.s64 	%rd37, %rd51, %rd26;
	mul.lo.s64 	%rd38, %rd37, %rd24;
	add.s64 	%rd39, %rd50, %rd27;
	add.s64 	%rd40, %rd39, %rd36;
	add.s64 	%rd41, %rd40, %rd38;
	shl.b64 	%rd42, %rd41, 32;
	shr.s64 	%rd43, %rd42, 30;
	add.s64 	%rd44, %rd3, %rd43;
	ld.global.f32 	%f1, [%rd44];
	shl.b64 	%rd45, %rd47, 2;
	add.s64 	%rd46, %rd4, %rd45;
	st.global.f32 	[%rd46], %f1;
	add.s64 	%rd47, %rd47, %rd2;
	setp.lt.u64 	%p5, %rd47, %rd19;
	@%p5 bra 	$L__BB1_2;

$L__BB1_12:
	ret;

}
	// .globl	constPadding3d
.visible .entry constPadding3d(
	.param .u64 constPadding3d_param_0,
	.param .u64 constPadding3d_param_1,
	.param .u64 constPadding3d_param_2,
	.param .u64 constPadding3d_param_3,
	.param .u64 constPadding3d_param_4,
	.param .u64 constPadding3d_param_5,
	.param .u64 constPadding3d_param_6,
	.param .u64 constPadding3d_param_7,
	.param .u64 constPadding3d_param_8,
	.param .u64 constPadding3d_param_9,
	.param .u64 constPadding3d_param_10,
	.param .u64 constPadding3d_param_11,
	.param .u64 constPadding3d_param_12,
	.param .u64 constPadding3d_param_13,
	.param .u64 constPadding3d_param_14,
	.param .u64 constPadding3d_param_15,
	.param .u64 constPadding3d_param_16,
	.param .f32 constPadding3d_param_17,
	.param .u64 constPadding3d_param_18
)
{
	.reg .pred 	%p<19>;
	.reg .f32 	%f<5>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<77>;


	ld.param.u64 	%rd27, [constPadding3d_param_0];
	ld.param.u64 	%rd28, [constPadding3d_param_1];
	ld.param.u64 	%rd29, [constPadding3d_param_4];
	ld.param.u64 	%rd30, [constPadding3d_param_5];
	ld.param.u64 	%rd31, [constPadding3d_param_6];
	ld.param.u64 	%rd32, [constPadding3d_param_7];
	ld.param.u64 	%rd33, [constPadding3d_param_8];
	ld.param.u64 	%rd34, [constPadding3d_param_9];
	ld.param.u64 	%rd35, [constPadding3d_param_10];
	ld.param.u64 	%rd36, [constPadding3d_param_11];
	ld.param.u64 	%rd37, [constPadding3d_param_12];
	ld.param.u64 	%rd38, [constPadding3d_param_13];
	ld.param.u64 	%rd39, [constPadding3d_param_14];
	ld.param.u64 	%rd40, [constPadding3d_param_15];
	ld.param.u64 	%rd41, [constPadding3d_param_16];
	ld.param.f32 	%f3, [constPadding3d_param_17];
	ld.param.u64 	%rd42, [constPadding3d_param_18];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd70, %r4;
	setp.ge.u64 	%p1, %rd70, %rd27;
	@%p1 bra 	$L__BB2_20;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd28;
	cvta.to.global.u64 	%rd4, %rd42;
	cvt.u32.u64 	%r7, %rd38;
	cvt.u32.u64 	%r10, %rd34;
	cvt.u32.u64 	%r13, %rd36;

$L__BB2_2:
	or.b64  	%rd43, %rd70, %rd38;
	and.b64  	%rd44, %rd43, -4294967296;
	setp.eq.s64 	%p2, %rd44, 0;
	@%p2 bra 	$L__BB2_4;

	div.u64 	%rd71, %rd70, %rd38;
	bra.uni 	$L__BB2_5;

$L__BB2_4:
	cvt.u32.u64 	%r8, %rd70;
	div.u32 	%r9, %r8, %r7;
	cvt.u64.u32 	%rd71, %r9;

$L__BB2_5:
	or.b64  	%rd45, %rd71, %rd34;
	and.b64  	%rd46, %rd45, -4294967296;
	setp.eq.s64 	%p3, %rd46, 0;
	@%p3 bra 	$L__BB2_7;

	rem.u64 	%rd72, %rd71, %rd34;
	bra.uni 	$L__BB2_8;

$L__BB2_7:
	cvt.u32.u64 	%r11, %rd71;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd72, %r12;

$L__BB2_8:
	or.b64  	%rd47, %rd70, %rd36;
	and.b64  	%rd48, %rd47, -4294967296;
	setp.eq.s64 	%p4, %rd48, 0;
	@%p4 bra 	$L__BB2_10;

	div.u64 	%rd73, %rd70, %rd36;
	mul.lo.s64 	%rd49, %rd73, %rd36;
	sub.s64 	%rd74, %rd70, %rd49;
	bra.uni 	$L__BB2_11;

$L__BB2_10:
	cvt.u32.u64 	%r14, %rd70;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd73, %r15;
	cvt.u64.u32 	%rd74, %r17;

$L__BB2_11:
	or.b64  	%rd50, %rd73, %rd35;
	and.b64  	%rd51, %rd50, -4294967296;
	setp.eq.s64 	%p5, %rd51, 0;
	@%p5 bra 	$L__BB2_13;

	rem.u64 	%rd75, %rd73, %rd35;
	bra.uni 	$L__BB2_14;

$L__BB2_13:
	cvt.u32.u64 	%r18, %rd35;
	cvt.u32.u64 	%r19, %rd73;
	rem.u32 	%r20, %r19, %r18;
	cvt.u64.u32 	%rd75, %r20;

$L__BB2_14:
	cvt.s64.s32 	%rd52, %rd72;
	setp.lt.s64 	%p6, %rd52, %rd39;
	cvt.s64.s32 	%rd53, %rd75;
	setp.lt.s64 	%p7, %rd53, %rd40;
	or.pred  	%p8, %p6, %p7;
	cvt.s64.s32 	%rd54, %rd74;
	setp.lt.s64 	%p9, %rd54, %rd41;
	or.pred  	%p10, %p8, %p9;
	sub.s64 	%rd21, %rd52, %rd39;
	setp.ge.s64 	%p11, %rd21, %rd29;
	or.pred  	%p12, %p11, %p10;
	sub.s64 	%rd22, %rd53, %rd40;
	setp.ge.s64 	%p13, %rd22, %rd30;
	or.pred  	%p14, %p13, %p12;
	sub.s64 	%rd55, %rd54, %rd41;
	setp.ge.s64 	%p15, %rd55, %rd31;
	or.pred  	%p16, %p15, %p14;
	mov.f32 	%f4, %f3;
	@%p16 bra 	$L__BB2_19;

	or.b64  	%rd56, %rd70, %rd37;
	and.b64  	%rd57, %rd56, -4294967296;
	setp.eq.s64 	%p17, %rd57, 0;
	@%p17 bra 	$L__BB2_17;

	div.u64 	%rd76, %rd70, %rd37;
	bra.uni 	$L__BB2_18;

$L__BB2_17:
	cvt.u32.u64 	%r21, %rd37;
	cvt.u32.u64 	%r22, %rd70;
	div.u32 	%r23, %r22, %r21;
	cvt.u64.u32 	%rd76, %r23;

$L__BB2_18:
	mul.lo.s64 	%rd58, %rd76, %rd32;
	sub.s64 	%rd59, %rd74, %rd41;
	mul.lo.s64 	%rd60, %rd21, %rd33;
	add.s64 	%rd61, %rd59, %rd60;
	mul.lo.s64 	%rd62, %rd22, %rd31;
	add.s64 	%rd63, %rd61, %rd62;
	add.s64 	%rd64, %rd63, %rd58;
	shl.b64 	%rd65, %rd64, 32;
	shr.s64 	%rd66, %rd65, 30;
	add.s64 	%rd67, %rd3, %rd66;
	ld.global.f32 	%f4, [%rd67];

$L__BB2_19:
	shl.b64 	%rd68, %rd70, 2;
	add.s64 	%rd69, %rd4, %rd68;
	st.global.f32 	[%rd69], %f4;
	add.s64 	%rd70, %rd70, %rd2;
	setp.lt.u64 	%p18, %rd70, %rd27;
	@%p18 bra 	$L__BB2_2;

$L__BB2_20:
	ret;

}
	// .globl	constPadding3d_seft
.visible .entry constPadding3d_seft(
	.param .u64 constPadding3d_seft_param_0,
	.param .u64 constPadding3d_seft_param_1,
	.param .u64 constPadding3d_seft_param_2,
	.param .u64 constPadding3d_seft_param_3,
	.param .u64 constPadding3d_seft_param_4,
	.param .u64 constPadding3d_seft_param_5,
	.param .u64 constPadding3d_seft_param_6,
	.param .u64 constPadding3d_seft_param_7,
	.param .u64 constPadding3d_seft_param_8,
	.param .u64 constPadding3d_seft_param_9,
	.param .u64 constPadding3d_seft_param_10,
	.param .u64 constPadding3d_seft_param_11,
	.param .u64 constPadding3d_seft_param_12,
	.param .u64 constPadding3d_seft_param_13,
	.param .u64 constPadding3d_seft_param_14,
	.param .u64 constPadding3d_seft_param_15,
	.param .u64 constPadding3d_seft_param_16,
	.param .u64 constPadding3d_seft_param_17
)
{
	.reg .pred 	%p<19>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<79>;


	ld.param.u64 	%rd25, [constPadding3d_seft_param_0];
	ld.param.u64 	%rd26, [constPadding3d_seft_param_1];
	ld.param.u64 	%rd27, [constPadding3d_seft_param_4];
	ld.param.u64 	%rd28, [constPadding3d_seft_param_5];
	ld.param.u64 	%rd29, [constPadding3d_seft_param_6];
	ld.param.u64 	%rd30, [constPadding3d_seft_param_7];
	ld.param.u64 	%rd31, [constPadding3d_seft_param_8];
	ld.param.u64 	%rd32, [constPadding3d_seft_param_9];
	ld.param.u64 	%rd33, [constPadding3d_seft_param_10];
	ld.param.u64 	%rd34, [constPadding3d_seft_param_11];
	ld.param.u64 	%rd35, [constPadding3d_seft_param_12];
	ld.param.u64 	%rd36, [constPadding3d_seft_param_13];
	ld.param.u64 	%rd37, [constPadding3d_seft_param_14];
	ld.param.u64 	%rd38, [constPadding3d_seft_param_15];
	ld.param.u64 	%rd39, [constPadding3d_seft_param_16];
	ld.param.u64 	%rd40, [constPadding3d_seft_param_17];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd72, %r4;
	setp.ge.u64 	%p1, %rd72, %rd25;
	@%p1 bra 	$L__BB3_18;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd26;
	cvta.to.global.u64 	%rd4, %rd40;
	cvt.u32.u64 	%r7, %rd36;
	cvt.u32.u64 	%r10, %rd32;
	cvt.u32.u64 	%r13, %rd34;

$L__BB3_2:
	or.b64  	%rd41, %rd72, %rd36;
	and.b64  	%rd42, %rd41, -4294967296;
	setp.eq.s64 	%p2, %rd42, 0;
	@%p2 bra 	$L__BB3_4;

	div.u64 	%rd73, %rd72, %rd36;
	bra.uni 	$L__BB3_5;

$L__BB3_4:
	cvt.u32.u64 	%r8, %rd72;
	div.u32 	%r9, %r8, %r7;
	cvt.u64.u32 	%rd73, %r9;

$L__BB3_5:
	or.b64  	%rd43, %rd73, %rd32;
	and.b64  	%rd44, %rd43, -4294967296;
	setp.eq.s64 	%p3, %rd44, 0;
	@%p3 bra 	$L__BB3_7;

	rem.u64 	%rd74, %rd73, %rd32;
	bra.uni 	$L__BB3_8;

$L__BB3_7:
	cvt.u32.u64 	%r11, %rd73;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd74, %r12;

$L__BB3_8:
	or.b64  	%rd45, %rd72, %rd34;
	and.b64  	%rd46, %rd45, -4294967296;
	setp.eq.s64 	%p4, %rd46, 0;
	@%p4 bra 	$L__BB3_10;

	div.u64 	%rd75, %rd72, %rd34;
	mul.lo.s64 	%rd47, %rd75, %rd34;
	sub.s64 	%rd76, %rd72, %rd47;
	bra.uni 	$L__BB3_11;

$L__BB3_10:
	cvt.u32.u64 	%r14, %rd72;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd75, %r15;
	cvt.u64.u32 	%rd76, %r17;

$L__BB3_11:
	or.b64  	%rd48, %rd75, %rd33;
	and.b64  	%rd49, %rd48, -4294967296;
	setp.eq.s64 	%p5, %rd49, 0;
	@%p5 bra 	$L__BB3_13;

	rem.u64 	%rd77, %rd75, %rd33;
	bra.uni 	$L__BB3_14;

$L__BB3_13:
	cvt.u32.u64 	%r18, %rd33;
	cvt.u32.u64 	%r19, %rd75;
	rem.u32 	%r20, %r19, %r18;
	cvt.u64.u32 	%rd77, %r20;

$L__BB3_14:
	or.b64  	%rd50, %rd72, %rd35;
	and.b64  	%rd51, %rd50, -4294967296;
	setp.eq.s64 	%p6, %rd51, 0;
	@%p6 bra 	$L__BB3_16;

	div.u64 	%rd78, %rd72, %rd35;
	bra.uni 	$L__BB3_17;

$L__BB3_16:
	cvt.u32.u64 	%r21, %rd35;
	cvt.u32.u64 	%r22, %rd72;
	div.u32 	%r23, %r22, %r21;
	cvt.u64.u32 	%rd78, %r23;

$L__BB3_17:
	cvt.s64.s32 	%rd52, %rd74;
	setp.lt.s64 	%p7, %rd52, %rd37;
	cvt.s64.s32 	%rd53, %rd77;
	setp.lt.s64 	%p8, %rd53, %rd38;
	or.pred  	%p9, %p7, %p8;
	cvt.s64.s32 	%rd54, %rd76;
	setp.lt.s64 	%p10, %rd54, %rd39;
	or.pred  	%p11, %p9, %p10;
	sub.s64 	%rd55, %rd52, %rd37;
	setp.ge.s64 	%p12, %rd55, %rd27;
	or.pred  	%p13, %p12, %p11;
	sub.s64 	%rd56, %rd53, %rd38;
	setp.ge.s64 	%p14, %rd56, %rd28;
	or.pred  	%p15, %p14, %p13;
	sub.s64 	%rd57, %rd54, %rd39;
	setp.ge.s64 	%p16, %rd57, %rd29;
	or.pred  	%p17, %p16, %p15;
	cvt.s64.s32 	%rd58, %rd78;
	mul.lo.s64 	%rd59, %rd58, %rd30;
	mul.lo.s64 	%rd60, %rd56, %rd29;
	mul.lo.s64 	%rd61, %rd55, %rd31;
	add.s64 	%rd62, %rd59, %rd61;
	selp.b64 	%rd63, %rd59, %rd62, %p17;
	sub.s64 	%rd64, %rd76, %rd39;
	add.s64 	%rd65, %rd64, %rd60;
	add.s64 	%rd66, %rd65, %rd63;
	shl.b64 	%rd67, %rd66, 32;
	shr.s64 	%rd68, %rd67, 30;
	add.s64 	%rd69, %rd3, %rd68;
	ld.global.f32 	%f1, [%rd69];
	shl.b64 	%rd70, %rd72, 2;
	add.s64 	%rd71, %rd4, %rd70;
	st.global.f32 	[%rd71], %f1;
	add.s64 	%rd72, %rd72, %rd2;
	setp.lt.u64 	%p18, %rd72, %rd25;
	@%p18 bra 	$L__BB3_2;

$L__BB3_18:
	ret;

}
	// .globl	ConstantPadGrad3d
.visible .entry ConstantPadGrad3d(
	.param .u64 ConstantPadGrad3d_param_0,
	.param .u64 ConstantPadGrad3d_param_1,
	.param .u64 ConstantPadGrad3d_param_2,
	.param .u64 ConstantPadGrad3d_param_3,
	.param .u64 ConstantPadGrad3d_param_4,
	.param .u64 ConstantPadGrad3d_param_5,
	.param .u64 ConstantPadGrad3d_param_6,
	.param .u64 ConstantPadGrad3d_param_7,
	.param .u64 ConstantPadGrad3d_param_8,
	.param .u64 ConstantPadGrad3d_param_9,
	.param .u64 ConstantPadGrad3d_param_10,
	.param .u64 ConstantPadGrad3d_param_11,
	.param .u64 ConstantPadGrad3d_param_12,
	.param .u64 ConstantPadGrad3d_param_13,
	.param .u64 ConstantPadGrad3d_param_14,
	.param .u64 ConstantPadGrad3d_param_15,
	.param .u64 ConstantPadGrad3d_param_16,
	.param .u64 ConstantPadGrad3d_param_17
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<72>;


	ld.param.u64 	%rd25, [ConstantPadGrad3d_param_0];
	ld.param.u64 	%rd26, [ConstantPadGrad3d_param_1];
	ld.param.u64 	%rd27, [ConstantPadGrad3d_param_4];
	ld.param.u64 	%rd28, [ConstantPadGrad3d_param_5];
	ld.param.u64 	%rd29, [ConstantPadGrad3d_param_6];
	ld.param.u64 	%rd30, [ConstantPadGrad3d_param_7];
	ld.param.u64 	%rd31, [ConstantPadGrad3d_param_8];
	ld.param.u64 	%rd32, [ConstantPadGrad3d_param_11];
	ld.param.u64 	%rd33, [ConstantPadGrad3d_param_12];
	ld.param.u64 	%rd34, [ConstantPadGrad3d_param_13];
	ld.param.u64 	%rd35, [ConstantPadGrad3d_param_14];
	ld.param.u64 	%rd36, [ConstantPadGrad3d_param_15];
	ld.param.u64 	%rd37, [ConstantPadGrad3d_param_16];
	ld.param.u64 	%rd38, [ConstantPadGrad3d_param_17];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd65, %r4;
	setp.ge.u64 	%p1, %rd65, %rd25;
	@%p1 bra 	$L__BB4_18;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd26;
	cvta.to.global.u64 	%rd4, %rd38;
	cvt.u32.u64 	%r7, %rd30;
	cvt.u32.u64 	%r10, %rd31;
	cvt.u32.u64 	%r13, %rd27;

$L__BB4_2:
	or.b64  	%rd39, %rd65, %rd30;
	and.b64  	%rd40, %rd39, -4294967296;
	setp.eq.s64 	%p2, %rd40, 0;
	@%p2 bra 	$L__BB4_4;

	div.u64 	%rd66, %rd65, %rd30;
	bra.uni 	$L__BB4_5;

$L__BB4_4:
	cvt.u32.u64 	%r8, %rd65;
	div.u32 	%r9, %r8, %r7;
	cvt.u64.u32 	%rd66, %r9;

$L__BB4_5:
	or.b64  	%rd41, %rd65, %rd31;
	and.b64  	%rd42, %rd41, -4294967296;
	setp.eq.s64 	%p3, %rd42, 0;
	@%p3 bra 	$L__BB4_7;

	div.u64 	%rd67, %rd65, %rd31;
	bra.uni 	$L__BB4_8;

$L__BB4_7:
	cvt.u32.u64 	%r11, %rd65;
	div.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd67, %r12;

$L__BB4_8:
	or.b64  	%rd43, %rd67, %rd27;
	and.b64  	%rd44, %rd43, -4294967296;
	setp.eq.s64 	%p4, %rd44, 0;
	@%p4 bra 	$L__BB4_10;

	rem.u64 	%rd68, %rd67, %rd27;
	bra.uni 	$L__BB4_11;

$L__BB4_10:
	cvt.u32.u64 	%r14, %rd67;
	rem.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd68, %r15;

$L__BB4_11:
	or.b64  	%rd45, %rd65, %rd29;
	and.b64  	%rd46, %rd45, -4294967296;
	setp.eq.s64 	%p5, %rd46, 0;
	@%p5 bra 	$L__BB4_13;

	div.u64 	%rd69, %rd65, %rd29;
	mul.lo.s64 	%rd47, %rd69, %rd29;
	sub.s64 	%rd70, %rd65, %rd47;
	bra.uni 	$L__BB4_14;

$L__BB4_13:
	cvt.u32.u64 	%r16, %rd29;
	cvt.u32.u64 	%r17, %rd65;
	div.u32 	%r18, %r17, %r16;
	mul.lo.s32 	%r19, %r18, %r16;
	sub.s32 	%r20, %r17, %r19;
	cvt.u64.u32 	%rd69, %r18;
	cvt.u64.u32 	%rd70, %r20;

$L__BB4_14:
	or.b64  	%rd48, %rd69, %rd28;
	and.b64  	%rd49, %rd48, -4294967296;
	setp.eq.s64 	%p6, %rd49, 0;
	@%p6 bra 	$L__BB4_16;

	rem.u64 	%rd71, %rd69, %rd28;
	bra.uni 	$L__BB4_17;

$L__BB4_16:
	cvt.u32.u64 	%r21, %rd28;
	cvt.u32.u64 	%r22, %rd69;
	rem.u32 	%r23, %r22, %r21;
	cvt.u64.u32 	%rd71, %r23;

$L__BB4_17:
	cvt.s64.s32 	%rd50, %rd66;
	mul.lo.s64 	%rd51, %rd50, %rd33;
	add.s64 	%rd52, %rd68, %rd35;
	mul.lo.s64 	%rd53, %rd52, %rd34;
	add.s64 	%rd54, %rd71, %rd36;
	mul.lo.s64 	%rd55, %rd54, %rd32;
	add.s64 	%rd56, %rd51, %rd37;
	add.s64 	%rd57, %rd56, %rd70;
	add.s64 	%rd58, %rd57, %rd53;
	add.s64 	%rd59, %rd58, %rd55;
	shl.b64 	%rd60, %rd59, 32;
	shr.s64 	%rd61, %rd60, 30;
	add.s64 	%rd62, %rd3, %rd61;
	ld.global.f32 	%f1, [%rd62];
	shl.b64 	%rd63, %rd65, 2;
	add.s64 	%rd64, %rd4, %rd63;
	st.global.f32 	[%rd64], %f1;
	add.s64 	%rd65, %rd65, %rd2;
	setp.lt.u64 	%p7, %rd65, %rd25;
	@%p7 bra 	$L__BB4_2;

$L__BB4_18:
	ret;

}
	// .globl	ConstantPadGrad3d_self
.visible .entry ConstantPadGrad3d_self(
	.param .u64 ConstantPadGrad3d_self_param_0,
	.param .u64 ConstantPadGrad3d_self_param_1,
	.param .u64 ConstantPadGrad3d_self_param_2,
	.param .u64 ConstantPadGrad3d_self_param_3,
	.param .u64 ConstantPadGrad3d_self_param_4,
	.param .u64 ConstantPadGrad3d_self_param_5,
	.param .u64 ConstantPadGrad3d_self_param_6,
	.param .u64 ConstantPadGrad3d_self_param_7,
	.param .u64 ConstantPadGrad3d_self_param_8,
	.param .u64 ConstantPadGrad3d_self_param_9,
	.param .u64 ConstantPadGrad3d_self_param_10,
	.param .u64 ConstantPadGrad3d_self_param_11,
	.param .u64 ConstantPadGrad3d_self_param_12,
	.param .u64 ConstantPadGrad3d_self_param_13,
	.param .u64 ConstantPadGrad3d_self_param_14,
	.param .u64 ConstantPadGrad3d_self_param_15,
	.param .u64 ConstantPadGrad3d_self_param_16,
	.param .u64 ConstantPadGrad3d_self_param_17
)
{
	.reg .pred 	%p<19>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<74>;


	ld.param.u64 	%rd26, [ConstantPadGrad3d_self_param_0];
	ld.param.u64 	%rd27, [ConstantPadGrad3d_self_param_1];
	ld.param.u64 	%rd28, [ConstantPadGrad3d_self_param_4];
	ld.param.u64 	%rd29, [ConstantPadGrad3d_self_param_5];
	ld.param.u64 	%rd30, [ConstantPadGrad3d_self_param_6];
	ld.param.u64 	%rd31, [ConstantPadGrad3d_self_param_7];
	ld.param.u64 	%rd32, [ConstantPadGrad3d_self_param_9];
	ld.param.u64 	%rd33, [ConstantPadGrad3d_self_param_10];
	ld.param.u64 	%rd34, [ConstantPadGrad3d_self_param_11];
	ld.param.u64 	%rd35, [ConstantPadGrad3d_self_param_12];
	ld.param.u64 	%rd36, [ConstantPadGrad3d_self_param_13];
	ld.param.u64 	%rd37, [ConstantPadGrad3d_self_param_14];
	ld.param.u64 	%rd38, [ConstantPadGrad3d_self_param_15];
	ld.param.u64 	%rd39, [ConstantPadGrad3d_self_param_16];
	ld.param.u64 	%rd40, [ConstantPadGrad3d_self_param_17];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	mad.lo.s32 	%r4, %r2, %r1, %r3;
	cvt.u64.u32 	%rd67, %r4;
	setp.ge.u64 	%p1, %rd67, %rd26;
	@%p1 bra 	$L__BB5_20;

	mov.u32 	%r5, %nctaid.x;
	mul.lo.s32 	%r6, %r1, %r5;
	cvt.u64.u32 	%rd2, %r6;
	cvta.to.global.u64 	%rd3, %rd27;
	cvta.to.global.u64 	%rd4, %rd40;
	cvt.u32.u64 	%r7, %rd36;
	cvt.u32.u64 	%r10, %rd32;
	cvt.u32.u64 	%r13, %rd34;

$L__BB5_2:
	or.b64  	%rd41, %rd67, %rd36;
	and.b64  	%rd42, %rd41, -4294967296;
	setp.eq.s64 	%p2, %rd42, 0;
	@%p2 bra 	$L__BB5_4;

	div.u64 	%rd68, %rd67, %rd36;
	bra.uni 	$L__BB5_5;

$L__BB5_4:
	cvt.u32.u64 	%r8, %rd67;
	div.u32 	%r9, %r8, %r7;
	cvt.u64.u32 	%rd68, %r9;

$L__BB5_5:
	or.b64  	%rd43, %rd68, %rd32;
	and.b64  	%rd44, %rd43, -4294967296;
	setp.eq.s64 	%p3, %rd44, 0;
	@%p3 bra 	$L__BB5_7;

	rem.u64 	%rd69, %rd68, %rd32;
	bra.uni 	$L__BB5_8;

$L__BB5_7:
	cvt.u32.u64 	%r11, %rd68;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd69, %r12;

$L__BB5_8:
	or.b64  	%rd45, %rd67, %rd34;
	and.b64  	%rd46, %rd45, -4294967296;
	setp.eq.s64 	%p4, %rd46, 0;
	@%p4 bra 	$L__BB5_10;

	div.u64 	%rd70, %rd67, %rd34;
	mul.lo.s64 	%rd47, %rd70, %rd34;
	sub.s64 	%rd71, %rd67, %rd47;
	bra.uni 	$L__BB5_11;

$L__BB5_10:
	cvt.u32.u64 	%r14, %rd67;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd70, %r15;
	cvt.u64.u32 	%rd71, %r17;

$L__BB5_11:
	or.b64  	%rd48, %rd70, %rd33;
	and.b64  	%rd49, %rd48, -4294967296;
	setp.eq.s64 	%p5, %rd49, 0;
	@%p5 bra 	$L__BB5_13;

	rem.u64 	%rd72, %rd70, %rd33;
	bra.uni 	$L__BB5_14;

$L__BB5_13:
	cvt.u32.u64 	%r18, %rd33;
	cvt.u32.u64 	%r19, %rd70;
	rem.u32 	%r20, %r19, %r18;
	cvt.u64.u32 	%rd72, %r20;

$L__BB5_14:
	or.b64  	%rd50, %rd67, %rd35;
	and.b64  	%rd51, %rd50, -4294967296;
	setp.eq.s64 	%p6, %rd51, 0;
	@%p6 bra 	$L__BB5_16;

	div.u64 	%rd73, %rd67, %rd35;
	bra.uni 	$L__BB5_17;

$L__BB5_16:
	cvt.u32.u64 	%r21, %rd35;
	cvt.u32.u64 	%r22, %rd67;
	div.u32 	%r23, %r22, %r21;
	cvt.u64.u32 	%rd73, %r23;

$L__BB5_17:
	cvt.s64.s32 	%rd52, %rd69;
	setp.ge.s64 	%p7, %rd52, %rd37;
	cvt.s64.s32 	%rd53, %rd72;
	setp.ge.s64 	%p8, %rd53, %rd38;
	and.pred  	%p9, %p7, %p8;
	cvt.s64.s32 	%rd54, %rd71;
	setp.ge.s64 	%p10, %rd54, %rd39;
	and.pred  	%p11, %p9, %p10;
	sub.s64 	%rd55, %rd52, %rd37;
	setp.lt.s64 	%p12, %rd55, %rd28;
	and.pred  	%p13, %p12, %p11;
	sub.s64 	%rd24, %rd53, %rd38;
	setp.lt.s64 	%p14, %rd24, %rd29;
	and.pred  	%p15, %p14, %p13;
	sub.s64 	%rd56, %rd54, %rd39;
	setp.lt.s64 	%p16, %rd56, %rd30;
	and.pred  	%p17, %p16, %p15;
	@%p17 bra 	$L__BB5_19;

	mul.lo.s64 	%rd57, %rd73, %rd31;
	sub.s64 	%rd58, %rd71, %rd39;
	mul.lo.s64 	%rd59, %rd24, %rd30;
	add.s64 	%rd60, %rd58, %rd59;
	add.s64 	%rd61, %rd60, %rd57;
	shl.b64 	%rd62, %rd61, 32;
	shr.s64 	%rd63, %rd62, 30;
	add.s64 	%rd64, %rd4, %rd63;
	shl.b64 	%rd65, %rd67, 2;
	add.s64 	%rd66, %rd3, %rd65;
	ld.global.f32 	%f1, [%rd66];
	atom.global.add.f32 	%f2, [%rd64], %f1;

$L__BB5_19:
	add.s64 	%rd67, %rd67, %rd2;
	setp.lt.u64 	%p18, %rd67, %rd26;
	@%p18 bra 	$L__BB5_2;

$L__BB5_20:
	ret;

}

