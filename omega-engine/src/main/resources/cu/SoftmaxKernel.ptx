//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31442593
// Cuda compilation tools, release 11.7, V11.7.99
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_52
.address_size 64

	// .globl	softmax

.visible .entry softmax(
	.param .u64 softmax_param_0,
	.param .u64 softmax_param_1,
	.param .u32 softmax_param_2,
	.param .u32 softmax_param_3
)
{
	.reg .pred 	%p<22>;
	.reg .f32 	%f<126>;
	.reg .b32 	%r<74>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd27, [softmax_param_0];
	ld.param.u64 	%rd28, [softmax_param_1];
	ld.param.u32 	%r30, [softmax_param_2];
	ld.param.u32 	%r29, [softmax_param_3];
	cvta.to.global.u64 	%rd1, %rd27;
	cvta.to.global.u64 	%rd2, %rd28;
	mov.u32 	%r31, %nctaid.x;
	mov.u32 	%r32, %ctaid.y;
	mov.u32 	%r33, %ctaid.x;
	mad.lo.s32 	%r34, %r32, %r31, %r33;
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %tid.x;
	mad.lo.s32 	%r1, %r34, %r35, %r36;
	setp.ge.s32 	%p1, %r1, %r30;
	@%p1 bra 	$L__BB0_22;

	setp.lt.s32 	%p2, %r29, 1;
	mov.f32 	%f120, 0fFF7FFFFF;
	@%p2 bra 	$L__BB0_8;

	add.s32 	%r38, %r29, -1;
	and.b32  	%r65, %r29, 3;
	setp.lt.u32 	%p3, %r38, 3;
	mov.f32 	%f120, 0fFF7FFFFF;
	mov.u32 	%r64, 0;
	@%p3 bra 	$L__BB0_5;

	sub.s32 	%r63, %r29, %r65;
	mul.lo.s32 	%r40, %r29, %r1;
	mul.wide.s32 	%rd29, %r40, 4;
	add.s64 	%rd30, %rd1, %rd29;
	add.s64 	%rd38, %rd30, 8;

$L__BB0_4:
	ld.global.f32 	%f19, [%rd38+-8];
	setp.le.f32 	%p4, %f120, %f19;
	selp.f32 	%f20, %f19, %f120, %p4;
	ld.global.f32 	%f21, [%rd38+-4];
	setp.le.f32 	%p5, %f20, %f21;
	selp.f32 	%f22, %f21, %f20, %p5;
	ld.global.f32 	%f23, [%rd38];
	setp.le.f32 	%p6, %f22, %f23;
	selp.f32 	%f24, %f23, %f22, %p6;
	ld.global.f32 	%f25, [%rd38+4];
	setp.le.f32 	%p7, %f24, %f25;
	selp.f32 	%f120, %f25, %f24, %p7;
	add.s32 	%r64, %r64, 4;
	add.s64 	%rd38, %rd38, 16;
	add.s32 	%r63, %r63, -4;
	setp.ne.s32 	%p8, %r63, 0;
	@%p8 bra 	$L__BB0_4;

$L__BB0_5:
	setp.eq.s32 	%p9, %r65, 0;
	@%p9 bra 	$L__BB0_8;

	mad.lo.s32 	%r41, %r29, %r1, %r64;
	mul.wide.s32 	%rd31, %r41, 4;
	add.s64 	%rd39, %rd1, %rd31;

$L__BB0_7:
	.pragma "nounroll";
	ld.global.f32 	%f26, [%rd39];
	setp.le.f32 	%p10, %f120, %f26;
	selp.f32 	%f120, %f26, %f120, %p10;
	add.s64 	%rd39, %rd39, 4;
	add.s32 	%r65, %r65, -1;
	setp.ne.s32 	%p11, %r65, 0;
	@%p11 bra 	$L__BB0_7;

$L__BB0_8:
	mov.f32 	%f125, 0f00000000;
	@%p2 bra 	$L__BB0_15;

	add.s32 	%r43, %r29, -1;
	and.b32  	%r69, %r29, 3;
	setp.lt.u32 	%p13, %r43, 3;
	mov.f32 	%f125, 0f00000000;
	mov.u32 	%r68, 0;
	@%p13 bra 	$L__BB0_12;

	sub.s32 	%r67, %r29, %r69;
	mul.lo.s32 	%r45, %r29, %r1;
	mul.wide.s32 	%rd32, %r45, 4;
	add.s64 	%rd33, %rd32, 8;
	add.s64 	%rd41, %rd1, %rd33;
	add.s64 	%rd40, %rd2, %rd33;
	mov.f32 	%f33, 0f3F000000;
	mov.f32 	%f34, 0f3BBB989D;

$L__BB0_11:
	ld.global.f32 	%f31, [%rd41+-8];
	sub.f32 	%f32, %f31, %f120;
	fma.rn.f32 	%f35, %f32, %f34, %f33;
	mov.f32 	%f36, 0f3FB8AA3B;
	mov.f32 	%f37, 0f437C0000;
	cvt.sat.f32.f32 	%f38, %f35;
	mov.f32 	%f39, 0f4B400001;
	fma.rm.f32 	%f40, %f38, %f37, %f39;
	add.f32 	%f41, %f40, 0fCB40007F;
	neg.f32 	%f42, %f41;
	fma.rn.f32 	%f43, %f32, %f36, %f42;
	mov.f32 	%f44, 0f32A57060;
	fma.rn.f32 	%f45, %f32, %f44, %f43;
	mov.b32 	%r46, %f40;
	shl.b32 	%r47, %r46, 23;
	mov.b32 	%f46, %r47;
	ex2.approx.ftz.f32 	%f47, %f45;
	mul.f32 	%f48, %f47, %f46;
	add.f32 	%f49, %f125, %f48;
	st.global.f32 	[%rd40+-8], %f48;
	ld.global.f32 	%f50, [%rd41+-4];
	sub.f32 	%f51, %f50, %f120;
	fma.rn.f32 	%f52, %f51, %f34, %f33;
	cvt.sat.f32.f32 	%f53, %f52;
	fma.rm.f32 	%f54, %f53, %f37, %f39;
	add.f32 	%f55, %f54, 0fCB40007F;
	neg.f32 	%f56, %f55;
	fma.rn.f32 	%f57, %f51, %f36, %f56;
	fma.rn.f32 	%f58, %f51, %f44, %f57;
	mov.b32 	%r48, %f54;
	shl.b32 	%r49, %r48, 23;
	mov.b32 	%f59, %r49;
	ex2.approx.ftz.f32 	%f60, %f58;
	mul.f32 	%f61, %f60, %f59;
	add.f32 	%f62, %f49, %f61;
	st.global.f32 	[%rd40+-4], %f61;
	ld.global.f32 	%f63, [%rd41];
	sub.f32 	%f64, %f63, %f120;
	fma.rn.f32 	%f65, %f64, %f34, %f33;
	cvt.sat.f32.f32 	%f66, %f65;
	fma.rm.f32 	%f67, %f66, %f37, %f39;
	add.f32 	%f68, %f67, 0fCB40007F;
	neg.f32 	%f69, %f68;
	fma.rn.f32 	%f70, %f64, %f36, %f69;
	fma.rn.f32 	%f71, %f64, %f44, %f70;
	mov.b32 	%r50, %f67;
	shl.b32 	%r51, %r50, 23;
	mov.b32 	%f72, %r51;
	ex2.approx.ftz.f32 	%f73, %f71;
	mul.f32 	%f74, %f73, %f72;
	add.f32 	%f75, %f62, %f74;
	st.global.f32 	[%rd40], %f74;
	ld.global.f32 	%f76, [%rd41+4];
	sub.f32 	%f77, %f76, %f120;
	fma.rn.f32 	%f78, %f77, %f34, %f33;
	cvt.sat.f32.f32 	%f79, %f78;
	fma.rm.f32 	%f80, %f79, %f37, %f39;
	add.f32 	%f81, %f80, 0fCB40007F;
	neg.f32 	%f82, %f81;
	fma.rn.f32 	%f83, %f77, %f36, %f82;
	fma.rn.f32 	%f84, %f77, %f44, %f83;
	mov.b32 	%r52, %f80;
	shl.b32 	%r53, %r52, 23;
	mov.b32 	%f85, %r53;
	ex2.approx.ftz.f32 	%f86, %f84;
	mul.f32 	%f87, %f86, %f85;
	add.f32 	%f125, %f75, %f87;
	st.global.f32 	[%rd40+4], %f87;
	add.s32 	%r68, %r68, 4;
	add.s64 	%rd41, %rd41, 16;
	add.s64 	%rd40, %rd40, 16;
	add.s32 	%r67, %r67, -4;
	setp.ne.s32 	%p14, %r67, 0;
	@%p14 bra 	$L__BB0_11;

$L__BB0_12:
	setp.eq.s32 	%p15, %r69, 0;
	@%p15 bra 	$L__BB0_15;

	mad.lo.s32 	%r54, %r29, %r1, %r68;
	mul.wide.s32 	%rd34, %r54, 4;
	add.s64 	%rd43, %rd2, %rd34;
	add.s64 	%rd42, %rd1, %rd34;
	mov.f32 	%f90, 0f3F000000;
	mov.f32 	%f91, 0f3BBB989D;

$L__BB0_14:
	.pragma "nounroll";
	ld.global.f32 	%f88, [%rd42];
	sub.f32 	%f89, %f88, %f120;
	fma.rn.f32 	%f92, %f89, %f91, %f90;
	mov.f32 	%f93, 0f3FB8AA3B;
	mov.f32 	%f94, 0f437C0000;
	cvt.sat.f32.f32 	%f95, %f92;
	mov.f32 	%f96, 0f4B400001;
	fma.rm.f32 	%f97, %f95, %f94, %f96;
	add.f32 	%f98, %f97, 0fCB40007F;
	neg.f32 	%f99, %f98;
	fma.rn.f32 	%f100, %f89, %f93, %f99;
	mov.f32 	%f101, 0f32A57060;
	fma.rn.f32 	%f102, %f89, %f101, %f100;
	mov.b32 	%r55, %f97;
	shl.b32 	%r56, %r55, 23;
	mov.b32 	%f103, %r56;
	ex2.approx.ftz.f32 	%f104, %f102;
	mul.f32 	%f105, %f104, %f103;
	add.f32 	%f125, %f125, %f105;
	st.global.f32 	[%rd43], %f105;
	add.s64 	%rd43, %rd43, 4;
	add.s64 	%rd42, %rd42, 4;
	add.s32 	%r69, %r69, -1;
	setp.ne.s32 	%p16, %r69, 0;
	@%p16 bra 	$L__BB0_14;

$L__BB0_15:
	@%p2 bra 	$L__BB0_22;

	add.s32 	%r58, %r29, -1;
	and.b32  	%r73, %r29, 3;
	setp.lt.u32 	%p18, %r58, 3;
	mov.u32 	%r72, 0;
	@%p18 bra 	$L__BB0_19;

	sub.s32 	%r71, %r29, %r73;
	mul.lo.s32 	%r60, %r29, %r1;
	mul.wide.s32 	%rd35, %r60, 4;
	add.s64 	%rd36, %rd2, %rd35;
	add.s64 	%rd44, %rd36, 8;

$L__BB0_18:
	ld.global.f32 	%f106, [%rd44+-8];
	div.rn.f32 	%f107, %f106, %f125;
	st.global.f32 	[%rd44+-8], %f107;
	ld.global.f32 	%f108, [%rd44+-4];
	div.rn.f32 	%f109, %f108, %f125;
	st.global.f32 	[%rd44+-4], %f109;
	ld.global.f32 	%f110, [%rd44];
	div.rn.f32 	%f111, %f110, %f125;
	st.global.f32 	[%rd44], %f111;
	ld.global.f32 	%f112, [%rd44+4];
	div.rn.f32 	%f113, %f112, %f125;
	st.global.f32 	[%rd44+4], %f113;
	add.s32 	%r72, %r72, 4;
	add.s64 	%rd44, %rd44, 16;
	add.s32 	%r71, %r71, -4;
	setp.ne.s32 	%p19, %r71, 0;
	@%p19 bra 	$L__BB0_18;

$L__BB0_19:
	setp.eq.s32 	%p20, %r73, 0;
	@%p20 bra 	$L__BB0_22;

	mad.lo.s32 	%r61, %r29, %r1, %r72;
	mul.wide.s32 	%rd37, %r61, 4;
	add.s64 	%rd45, %rd2, %rd37;

$L__BB0_21:
	.pragma "nounroll";
	ld.global.f32 	%f114, [%rd45];
	div.rn.f32 	%f115, %f114, %f125;
	st.global.f32 	[%rd45], %f115;
	add.s64 	%rd45, %rd45, 4;
	add.s32 	%r73, %r73, -1;
	setp.ne.s32 	%p21, %r73, 0;
	@%p21 bra 	$L__BB0_21;

$L__BB0_22:
	ret;

}
	// .globl	softmax_mask
.visible .entry softmax_mask(
	.param .u64 softmax_mask_param_0,
	.param .u64 softmax_mask_param_1,
	.param .u64 softmax_mask_param_2,
	.param .u32 softmax_mask_param_3,
	.param .u32 softmax_mask_param_4,
	.param .f32 softmax_mask_param_5
)
{
	.reg .pred 	%p<32>;
	.reg .f32 	%f<147>;
	.reg .b32 	%r<74>;
	.reg .b64 	%rd<64>;


	ld.param.u64 	%rd40, [softmax_mask_param_0];
	ld.param.u64 	%rd41, [softmax_mask_param_1];
	ld.param.u64 	%rd42, [softmax_mask_param_2];
	ld.param.u32 	%r30, [softmax_mask_param_3];
	ld.param.u32 	%r29, [softmax_mask_param_4];
	ld.param.f32 	%f15, [softmax_mask_param_5];
	cvta.to.global.u64 	%rd1, %rd42;
	cvta.to.global.u64 	%rd2, %rd40;
	cvta.to.global.u64 	%rd3, %rd41;
	mov.u32 	%r31, %nctaid.x;
	mov.u32 	%r32, %ctaid.y;
	mov.u32 	%r33, %ctaid.x;
	mad.lo.s32 	%r34, %r32, %r31, %r33;
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %tid.x;
	mad.lo.s32 	%r1, %r34, %r35, %r36;
	setp.ge.s32 	%p1, %r1, %r30;
	@%p1 bra 	$L__BB1_22;

	setp.lt.s32 	%p2, %r29, 1;
	mov.f32 	%f141, 0fFF7FFFFF;
	@%p2 bra 	$L__BB1_8;

	add.s32 	%r38, %r29, -1;
	and.b32  	%r65, %r29, 3;
	setp.lt.u32 	%p3, %r38, 3;
	mov.f32 	%f141, 0fFF7FFFFF;
	mov.u32 	%r64, 0;
	@%p3 bra 	$L__BB1_5;

	sub.s32 	%r63, %r29, %r65;
	mul.lo.s32 	%r40, %r29, %r1;
	mul.wide.s32 	%rd43, %r40, 4;
	add.s64 	%rd44, %rd43, 8;
	add.s64 	%rd53, %rd2, %rd44;
	add.s64 	%rd52, %rd1, %rd44;

$L__BB1_4:
	ld.global.f32 	%f20, [%rd52+-8];
	setp.eq.f32 	%p4, %f20, 0f3F800000;
	ld.global.f32 	%f21, [%rd53+-8];
	selp.f32 	%f22, %f15, %f21, %p4;
	setp.le.f32 	%p5, %f141, %f22;
	selp.f32 	%f23, %f22, %f141, %p5;
	ld.global.f32 	%f24, [%rd52+-4];
	setp.eq.f32 	%p6, %f24, 0f3F800000;
	ld.global.f32 	%f25, [%rd53+-4];
	selp.f32 	%f26, %f15, %f25, %p6;
	setp.le.f32 	%p7, %f23, %f26;
	selp.f32 	%f27, %f26, %f23, %p7;
	ld.global.f32 	%f28, [%rd52];
	setp.eq.f32 	%p8, %f28, 0f3F800000;
	ld.global.f32 	%f29, [%rd53];
	selp.f32 	%f30, %f15, %f29, %p8;
	setp.le.f32 	%p9, %f27, %f30;
	selp.f32 	%f31, %f30, %f27, %p9;
	ld.global.f32 	%f32, [%rd52+4];
	setp.eq.f32 	%p10, %f32, 0f3F800000;
	ld.global.f32 	%f33, [%rd53+4];
	selp.f32 	%f34, %f15, %f33, %p10;
	setp.le.f32 	%p11, %f31, %f34;
	selp.f32 	%f141, %f34, %f31, %p11;
	add.s32 	%r64, %r64, 4;
	add.s64 	%rd53, %rd53, 16;
	add.s64 	%rd52, %rd52, 16;
	add.s32 	%r63, %r63, -4;
	setp.ne.s32 	%p12, %r63, 0;
	@%p12 bra 	$L__BB1_4;

$L__BB1_5:
	setp.eq.s32 	%p13, %r65, 0;
	@%p13 bra 	$L__BB1_8;

	mad.lo.s32 	%r41, %r29, %r1, %r64;
	mul.wide.s32 	%rd45, %r41, 4;
	add.s64 	%rd55, %rd1, %rd45;
	add.s64 	%rd54, %rd2, %rd45;

$L__BB1_7:
	.pragma "nounroll";
	ld.global.f32 	%f35, [%rd55];
	setp.eq.f32 	%p14, %f35, 0f3F800000;
	ld.global.f32 	%f36, [%rd54];
	selp.f32 	%f37, %f15, %f36, %p14;
	setp.le.f32 	%p15, %f141, %f37;
	selp.f32 	%f141, %f37, %f141, %p15;
	add.s64 	%rd55, %rd55, 4;
	add.s64 	%rd54, %rd54, 4;
	add.s32 	%r65, %r65, -1;
	setp.ne.s32 	%p16, %r65, 0;
	@%p16 bra 	$L__BB1_7;

$L__BB1_8:
	mov.f32 	%f146, 0f00000000;
	@%p2 bra 	$L__BB1_15;

	add.s32 	%r43, %r29, -1;
	and.b32  	%r69, %r29, 3;
	setp.lt.u32 	%p18, %r43, 3;
	mov.f32 	%f146, 0f00000000;
	mov.u32 	%r68, 0;
	@%p18 bra 	$L__BB1_12;

	sub.s32 	%r67, %r29, %r69;
	mul.lo.s32 	%r45, %r29, %r1;
	mul.wide.s32 	%rd46, %r45, 4;
	add.s64 	%rd47, %rd46, 8;
	add.s64 	%rd58, %rd1, %rd47;
	add.s64 	%rd57, %rd2, %rd47;
	add.s64 	%rd56, %rd3, %rd47;
	mov.f32 	%f46, 0f3F000000;
	mov.f32 	%f47, 0f3BBB989D;

$L__BB1_11:
	ld.global.f32 	%f42, [%rd58+-8];
	setp.eq.f32 	%p19, %f42, 0f3F800000;
	ld.global.f32 	%f43, [%rd57+-8];
	selp.f32 	%f44, %f15, %f43, %p19;
	sub.f32 	%f45, %f44, %f141;
	fma.rn.f32 	%f48, %f45, %f47, %f46;
	mov.f32 	%f49, 0f3FB8AA3B;
	mov.f32 	%f50, 0f437C0000;
	cvt.sat.f32.f32 	%f51, %f48;
	mov.f32 	%f52, 0f4B400001;
	fma.rm.f32 	%f53, %f51, %f50, %f52;
	add.f32 	%f54, %f53, 0fCB40007F;
	neg.f32 	%f55, %f54;
	fma.rn.f32 	%f56, %f45, %f49, %f55;
	mov.f32 	%f57, 0f32A57060;
	fma.rn.f32 	%f58, %f45, %f57, %f56;
	mov.b32 	%r46, %f53;
	shl.b32 	%r47, %r46, 23;
	mov.b32 	%f59, %r47;
	ex2.approx.ftz.f32 	%f60, %f58;
	mul.f32 	%f61, %f60, %f59;
	add.f32 	%f62, %f146, %f61;
	st.global.f32 	[%rd56+-8], %f61;
	ld.global.f32 	%f63, [%rd58+-4];
	setp.eq.f32 	%p20, %f63, 0f3F800000;
	ld.global.f32 	%f64, [%rd57+-4];
	selp.f32 	%f65, %f15, %f64, %p20;
	sub.f32 	%f66, %f65, %f141;
	fma.rn.f32 	%f67, %f66, %f47, %f46;
	cvt.sat.f32.f32 	%f68, %f67;
	fma.rm.f32 	%f69, %f68, %f50, %f52;
	add.f32 	%f70, %f69, 0fCB40007F;
	neg.f32 	%f71, %f70;
	fma.rn.f32 	%f72, %f66, %f49, %f71;
	fma.rn.f32 	%f73, %f66, %f57, %f72;
	mov.b32 	%r48, %f69;
	shl.b32 	%r49, %r48, 23;
	mov.b32 	%f74, %r49;
	ex2.approx.ftz.f32 	%f75, %f73;
	mul.f32 	%f76, %f75, %f74;
	add.f32 	%f77, %f62, %f76;
	st.global.f32 	[%rd56+-4], %f76;
	ld.global.f32 	%f78, [%rd58];
	setp.eq.f32 	%p21, %f78, 0f3F800000;
	ld.global.f32 	%f79, [%rd57];
	selp.f32 	%f80, %f15, %f79, %p21;
	sub.f32 	%f81, %f80, %f141;
	fma.rn.f32 	%f82, %f81, %f47, %f46;
	cvt.sat.f32.f32 	%f83, %f82;
	fma.rm.f32 	%f84, %f83, %f50, %f52;
	add.f32 	%f85, %f84, 0fCB40007F;
	neg.f32 	%f86, %f85;
	fma.rn.f32 	%f87, %f81, %f49, %f86;
	fma.rn.f32 	%f88, %f81, %f57, %f87;
	mov.b32 	%r50, %f84;
	shl.b32 	%r51, %r50, 23;
	mov.b32 	%f89, %r51;
	ex2.approx.ftz.f32 	%f90, %f88;
	mul.f32 	%f91, %f90, %f89;
	add.f32 	%f92, %f77, %f91;
	st.global.f32 	[%rd56], %f91;
	ld.global.f32 	%f93, [%rd58+4];
	setp.eq.f32 	%p22, %f93, 0f3F800000;
	ld.global.f32 	%f94, [%rd57+4];
	selp.f32 	%f95, %f15, %f94, %p22;
	sub.f32 	%f96, %f95, %f141;
	fma.rn.f32 	%f97, %f96, %f47, %f46;
	cvt.sat.f32.f32 	%f98, %f97;
	fma.rm.f32 	%f99, %f98, %f50, %f52;
	add.f32 	%f100, %f99, 0fCB40007F;
	neg.f32 	%f101, %f100;
	fma.rn.f32 	%f102, %f96, %f49, %f101;
	fma.rn.f32 	%f103, %f96, %f57, %f102;
	mov.b32 	%r52, %f99;
	shl.b32 	%r53, %r52, 23;
	mov.b32 	%f104, %r53;
	ex2.approx.ftz.f32 	%f105, %f103;
	mul.f32 	%f106, %f105, %f104;
	add.f32 	%f146, %f92, %f106;
	st.global.f32 	[%rd56+4], %f106;
	add.s32 	%r68, %r68, 4;
	add.s64 	%rd58, %rd58, 16;
	add.s64 	%rd57, %rd57, 16;
	add.s64 	%rd56, %rd56, 16;
	add.s32 	%r67, %r67, -4;
	setp.ne.s32 	%p23, %r67, 0;
	@%p23 bra 	$L__BB1_11;

$L__BB1_12:
	setp.eq.s32 	%p24, %r69, 0;
	@%p24 bra 	$L__BB1_15;

	mad.lo.s32 	%r54, %r29, %r1, %r68;
	mul.wide.s32 	%rd48, %r54, 4;
	add.s64 	%rd61, %rd3, %rd48;
	add.s64 	%rd60, %rd1, %rd48;
	add.s64 	%rd59, %rd2, %rd48;
	mov.f32 	%f111, 0f3F000000;
	mov.f32 	%f112, 0f3BBB989D;

$L__BB1_14:
	.pragma "nounroll";
	ld.global.f32 	%f107, [%rd60];
	setp.eq.f32 	%p25, %f107, 0f3F800000;
	ld.global.f32 	%f108, [%rd59];
	selp.f32 	%f109, %f15, %f108, %p25;
	sub.f32 	%f110, %f109, %f141;
	fma.rn.f32 	%f113, %f110, %f112, %f111;
	mov.f32 	%f114, 0f3FB8AA3B;
	mov.f32 	%f115, 0f437C0000;
	cvt.sat.f32.f32 	%f116, %f113;
	mov.f32 	%f117, 0f4B400001;
	fma.rm.f32 	%f118, %f116, %f115, %f117;
	add.f32 	%f119, %f118, 0fCB40007F;
	neg.f32 	%f120, %f119;
	fma.rn.f32 	%f121, %f110, %f114, %f120;
	mov.f32 	%f122, 0f32A57060;
	fma.rn.f32 	%f123, %f110, %f122, %f121;
	mov.b32 	%r55, %f118;
	shl.b32 	%r56, %r55, 23;
	mov.b32 	%f124, %r56;
	ex2.approx.ftz.f32 	%f125, %f123;
	mul.f32 	%f126, %f125, %f124;
	add.f32 	%f146, %f146, %f126;
	st.global.f32 	[%rd61], %f126;
	add.s64 	%rd61, %rd61, 4;
	add.s64 	%rd60, %rd60, 4;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r69, %r69, -1;
	setp.ne.s32 	%p26, %r69, 0;
	@%p26 bra 	$L__BB1_14;

$L__BB1_15:
	@%p2 bra 	$L__BB1_22;

	add.s32 	%r58, %r29, -1;
	and.b32  	%r73, %r29, 3;
	setp.lt.u32 	%p28, %r58, 3;
	mov.u32 	%r72, 0;
	@%p28 bra 	$L__BB1_19;

	sub.s32 	%r71, %r29, %r73;
	mul.lo.s32 	%r60, %r29, %r1;
	mul.wide.s32 	%rd49, %r60, 4;
	add.s64 	%rd50, %rd3, %rd49;
	add.s64 	%rd62, %rd50, 8;

$L__BB1_18:
	ld.global.f32 	%f127, [%rd62+-8];
	div.rn.f32 	%f128, %f127, %f146;
	st.global.f32 	[%rd62+-8], %f128;
	ld.global.f32 	%f129, [%rd62+-4];
	div.rn.f32 	%f130, %f129, %f146;
	st.global.f32 	[%rd62+-4], %f130;
	ld.global.f32 	%f131, [%rd62];
	div.rn.f32 	%f132, %f131, %f146;
	st.global.f32 	[%rd62], %f132;
	ld.global.f32 	%f133, [%rd62+4];
	div.rn.f32 	%f134, %f133, %f146;
	st.global.f32 	[%rd62+4], %f134;
	add.s32 	%r72, %r72, 4;
	add.s64 	%rd62, %rd62, 16;
	add.s32 	%r71, %r71, -4;
	setp.ne.s32 	%p29, %r71, 0;
	@%p29 bra 	$L__BB1_18;

$L__BB1_19:
	setp.eq.s32 	%p30, %r73, 0;
	@%p30 bra 	$L__BB1_22;

	mad.lo.s32 	%r61, %r29, %r1, %r72;
	mul.wide.s32 	%rd51, %r61, 4;
	add.s64 	%rd63, %rd3, %rd51;

$L__BB1_21:
	.pragma "nounroll";
	ld.global.f32 	%f135, [%rd63];
	div.rn.f32 	%f136, %f135, %f146;
	st.global.f32 	[%rd63], %f136;
	add.s64 	%rd63, %rd63, 4;
	add.s32 	%r73, %r73, -1;
	setp.ne.s32 	%p31, %r73, 0;
	@%p31 bra 	$L__BB1_21;

$L__BB1_22:
	ret;

}
	// .globl	softmaxWithTemp
.visible .entry softmaxWithTemp(
	.param .u64 softmaxWithTemp_param_0,
	.param .u64 softmaxWithTemp_param_1,
	.param .u32 softmaxWithTemp_param_2,
	.param .u32 softmaxWithTemp_param_3,
	.param .f32 softmaxWithTemp_param_4
)
{
	.reg .pred 	%p<22>;
	.reg .f32 	%f<133>;
	.reg .b32 	%r<74>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd27, [softmaxWithTemp_param_0];
	ld.param.u64 	%rd28, [softmaxWithTemp_param_1];
	ld.param.u32 	%r30, [softmaxWithTemp_param_2];
	ld.param.u32 	%r29, [softmaxWithTemp_param_3];
	ld.param.f32 	%f16, [softmaxWithTemp_param_4];
	cvta.to.global.u64 	%rd1, %rd27;
	cvta.to.global.u64 	%rd2, %rd28;
	mov.u32 	%r31, %nctaid.x;
	mov.u32 	%r32, %ctaid.y;
	mov.u32 	%r33, %ctaid.x;
	mad.lo.s32 	%r34, %r32, %r31, %r33;
	mov.u32 	%r35, %ntid.x;
	mov.u32 	%r36, %tid.x;
	mad.lo.s32 	%r1, %r34, %r35, %r36;
	setp.ge.s32 	%p1, %r1, %r30;
	@%p1 bra 	$L__BB2_22;

	setp.lt.s32 	%p2, %r29, 1;
	mov.f32 	%f127, 0fFF7FFFFF;
	@%p2 bra 	$L__BB2_8;

	add.s32 	%r38, %r29, -1;
	and.b32  	%r65, %r29, 3;
	setp.lt.u32 	%p3, %r38, 3;
	mov.f32 	%f127, 0fFF7FFFFF;
	mov.u32 	%r64, 0;
	@%p3 bra 	$L__BB2_5;

	sub.s32 	%r63, %r29, %r65;
	mul.lo.s32 	%r40, %r29, %r1;
	mul.wide.s32 	%rd29, %r40, 4;
	add.s64 	%rd30, %rd1, %rd29;
	add.s64 	%rd38, %rd30, 8;

$L__BB2_4:
	ld.global.f32 	%f21, [%rd38+-8];
	setp.le.f32 	%p4, %f127, %f21;
	selp.f32 	%f22, %f21, %f127, %p4;
	ld.global.f32 	%f23, [%rd38+-4];
	setp.le.f32 	%p5, %f22, %f23;
	selp.f32 	%f24, %f23, %f22, %p5;
	ld.global.f32 	%f25, [%rd38];
	setp.le.f32 	%p6, %f24, %f25;
	selp.f32 	%f26, %f25, %f24, %p6;
	ld.global.f32 	%f27, [%rd38+4];
	setp.le.f32 	%p7, %f26, %f27;
	selp.f32 	%f127, %f27, %f26, %p7;
	add.s32 	%r64, %r64, 4;
	add.s64 	%rd38, %rd38, 16;
	add.s32 	%r63, %r63, -4;
	setp.ne.s32 	%p8, %r63, 0;
	@%p8 bra 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p9, %r65, 0;
	@%p9 bra 	$L__BB2_8;

	mad.lo.s32 	%r41, %r29, %r1, %r64;
	mul.wide.s32 	%rd31, %r41, 4;
	add.s64 	%rd39, %rd1, %rd31;

$L__BB2_7:
	.pragma "nounroll";
	ld.global.f32 	%f28, [%rd39];
	setp.le.f32 	%p10, %f127, %f28;
	selp.f32 	%f127, %f28, %f127, %p10;
	add.s64 	%rd39, %rd39, 4;
	add.s32 	%r65, %r65, -1;
	setp.ne.s32 	%p11, %r65, 0;
	@%p11 bra 	$L__BB2_7;

$L__BB2_8:
	mov.f32 	%f132, 0f00000000;
	@%p2 bra 	$L__BB2_15;

	div.rn.f32 	%f8, %f127, %f16;
	and.b32  	%r69, %r29, 3;
	add.s32 	%r43, %r29, -1;
	setp.lt.u32 	%p13, %r43, 3;
	mov.f32 	%f132, 0f00000000;
	mov.u32 	%r68, 0;
	@%p13 bra 	$L__BB2_12;

	sub.s32 	%r67, %r29, %r69;
	mul.lo.s32 	%r45, %r29, %r1;
	mul.wide.s32 	%rd32, %r45, 4;
	add.s64 	%rd33, %rd32, 8;
	add.s64 	%rd41, %rd1, %rd33;
	add.s64 	%rd40, %rd2, %rd33;

$L__BB2_11:
	ld.global.f32 	%f33, [%rd41+-8];
	div.rn.f32 	%f34, %f33, %f16;
	sub.f32 	%f35, %f34, %f8;
	mov.f32 	%f36, 0f3F000000;
	mov.f32 	%f37, 0f3BBB989D;
	fma.rn.f32 	%f38, %f35, %f37, %f36;
	mov.f32 	%f39, 0f3FB8AA3B;
	mov.f32 	%f40, 0f437C0000;
	cvt.sat.f32.f32 	%f41, %f38;
	mov.f32 	%f42, 0f4B400001;
	fma.rm.f32 	%f43, %f41, %f40, %f42;
	add.f32 	%f44, %f43, 0fCB40007F;
	neg.f32 	%f45, %f44;
	fma.rn.f32 	%f46, %f35, %f39, %f45;
	mov.f32 	%f47, 0f32A57060;
	fma.rn.f32 	%f48, %f35, %f47, %f46;
	mov.b32 	%r46, %f43;
	shl.b32 	%r47, %r46, 23;
	mov.b32 	%f49, %r47;
	ex2.approx.ftz.f32 	%f50, %f48;
	mul.f32 	%f51, %f50, %f49;
	add.f32 	%f52, %f132, %f51;
	st.global.f32 	[%rd40+-8], %f51;
	ld.global.f32 	%f53, [%rd41+-4];
	div.rn.f32 	%f54, %f53, %f16;
	sub.f32 	%f55, %f54, %f8;
	fma.rn.f32 	%f56, %f55, %f37, %f36;
	cvt.sat.f32.f32 	%f57, %f56;
	fma.rm.f32 	%f58, %f57, %f40, %f42;
	add.f32 	%f59, %f58, 0fCB40007F;
	neg.f32 	%f60, %f59;
	fma.rn.f32 	%f61, %f55, %f39, %f60;
	fma.rn.f32 	%f62, %f55, %f47, %f61;
	mov.b32 	%r48, %f58;
	shl.b32 	%r49, %r48, 23;
	mov.b32 	%f63, %r49;
	ex2.approx.ftz.f32 	%f64, %f62;
	mul.f32 	%f65, %f64, %f63;
	add.f32 	%f66, %f52, %f65;
	st.global.f32 	[%rd40+-4], %f65;
	ld.global.f32 	%f67, [%rd41];
	div.rn.f32 	%f68, %f67, %f16;
	sub.f32 	%f69, %f68, %f8;
	fma.rn.f32 	%f70, %f69, %f37, %f36;
	cvt.sat.f32.f32 	%f71, %f70;
	fma.rm.f32 	%f72, %f71, %f40, %f42;
	add.f32 	%f73, %f72, 0fCB40007F;
	neg.f32 	%f74, %f73;
	fma.rn.f32 	%f75, %f69, %f39, %f74;
	fma.rn.f32 	%f76, %f69, %f47, %f75;
	mov.b32 	%r50, %f72;
	shl.b32 	%r51, %r50, 23;
	mov.b32 	%f77, %r51;
	ex2.approx.ftz.f32 	%f78, %f76;
	mul.f32 	%f79, %f78, %f77;
	add.f32 	%f80, %f66, %f79;
	st.global.f32 	[%rd40], %f79;
	ld.global.f32 	%f81, [%rd41+4];
	div.rn.f32 	%f82, %f81, %f16;
	sub.f32 	%f83, %f82, %f8;
	fma.rn.f32 	%f84, %f83, %f37, %f36;
	cvt.sat.f32.f32 	%f85, %f84;
	fma.rm.f32 	%f86, %f85, %f40, %f42;
	add.f32 	%f87, %f86, 0fCB40007F;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f89, %f83, %f39, %f88;
	fma.rn.f32 	%f90, %f83, %f47, %f89;
	mov.b32 	%r52, %f86;
	shl.b32 	%r53, %r52, 23;
	mov.b32 	%f91, %r53;
	ex2.approx.ftz.f32 	%f92, %f90;
	mul.f32 	%f93, %f92, %f91;
	add.f32 	%f132, %f80, %f93;
	st.global.f32 	[%rd40+4], %f93;
	add.s32 	%r68, %r68, 4;
	add.s64 	%rd41, %rd41, 16;
	add.s64 	%rd40, %rd40, 16;
	add.s32 	%r67, %r67, -4;
	setp.ne.s32 	%p14, %r67, 0;
	@%p14 bra 	$L__BB2_11;

$L__BB2_12:
	setp.eq.s32 	%p15, %r69, 0;
	@%p15 bra 	$L__BB2_15;

	mad.lo.s32 	%r54, %r29, %r1, %r68;
	mul.wide.s32 	%rd34, %r54, 4;
	add.s64 	%rd43, %rd2, %rd34;
	add.s64 	%rd42, %rd1, %rd34;
	mov.f32 	%f97, 0f3F000000;
	mov.f32 	%f98, 0f3BBB989D;

$L__BB2_14:
	.pragma "nounroll";
	ld.global.f32 	%f94, [%rd42];
	div.rn.f32 	%f95, %f94, %f16;
	sub.f32 	%f96, %f95, %f8;
	fma.rn.f32 	%f99, %f96, %f98, %f97;
	mov.f32 	%f100, 0f3FB8AA3B;
	mov.f32 	%f101, 0f437C0000;
	cvt.sat.f32.f32 	%f102, %f99;
	mov.f32 	%f103, 0f4B400001;
	fma.rm.f32 	%f104, %f102, %f101, %f103;
	add.f32 	%f105, %f104, 0fCB40007F;
	neg.f32 	%f106, %f105;
	fma.rn.f32 	%f107, %f96, %f100, %f106;
	mov.f32 	%f108, 0f32A57060;
	fma.rn.f32 	%f109, %f96, %f108, %f107;
	mov.b32 	%r55, %f104;
	shl.b32 	%r56, %r55, 23;
	mov.b32 	%f110, %r56;
	ex2.approx.ftz.f32 	%f111, %f109;
	mul.f32 	%f112, %f111, %f110;
	add.f32 	%f132, %f132, %f112;
	st.global.f32 	[%rd43], %f112;
	add.s64 	%rd43, %rd43, 4;
	add.s64 	%rd42, %rd42, 4;
	add.s32 	%r69, %r69, -1;
	setp.ne.s32 	%p16, %r69, 0;
	@%p16 bra 	$L__BB2_14;

$L__BB2_15:
	@%p2 bra 	$L__BB2_22;

	add.s32 	%r58, %r29, -1;
	and.b32  	%r73, %r29, 3;
	setp.lt.u32 	%p18, %r58, 3;
	mov.u32 	%r72, 0;
	@%p18 bra 	$L__BB2_19;

	sub.s32 	%r71, %r29, %r73;
	mul.lo.s32 	%r60, %r29, %r1;
	mul.wide.s32 	%rd35, %r60, 4;
	add.s64 	%rd36, %rd2, %rd35;
	add.s64 	%rd44, %rd36, 8;

$L__BB2_18:
	ld.global.f32 	%f113, [%rd44+-8];
	div.rn.f32 	%f114, %f113, %f132;
	st.global.f32 	[%rd44+-8], %f114;
	ld.global.f32 	%f115, [%rd44+-4];
	div.rn.f32 	%f116, %f115, %f132;
	st.global.f32 	[%rd44+-4], %f116;
	ld.global.f32 	%f117, [%rd44];
	div.rn.f32 	%f118, %f117, %f132;
	st.global.f32 	[%rd44], %f118;
	ld.global.f32 	%f119, [%rd44+4];
	div.rn.f32 	%f120, %f119, %f132;
	st.global.f32 	[%rd44+4], %f120;
	add.s32 	%r72, %r72, 4;
	add.s64 	%rd44, %rd44, 16;
	add.s32 	%r71, %r71, -4;
	setp.ne.s32 	%p19, %r71, 0;
	@%p19 bra 	$L__BB2_18;

$L__BB2_19:
	setp.eq.s32 	%p20, %r73, 0;
	@%p20 bra 	$L__BB2_22;

	mad.lo.s32 	%r61, %r29, %r1, %r72;
	mul.wide.s32 	%rd37, %r61, 4;
	add.s64 	%rd45, %rd2, %rd37;

$L__BB2_21:
	.pragma "nounroll";
	ld.global.f32 	%f121, [%rd45];
	div.rn.f32 	%f122, %f121, %f132;
	st.global.f32 	[%rd45], %f122;
	add.s64 	%rd45, %rd45, 4;
	add.s32 	%r73, %r73, -1;
	setp.ne.s32 	%p21, %r73, 0;
	@%p21 bra 	$L__BB2_21;

$L__BB2_22:
	ret;

}
	// .globl	log_softmax
.visible .entry log_softmax(
	.param .u64 log_softmax_param_0,
	.param .u64 log_softmax_param_1,
	.param .u32 log_softmax_param_2,
	.param .u32 log_softmax_param_3
)
{
	.reg .pred 	%p<33>;
	.reg .f32 	%f<175>;
	.reg .b32 	%r<78>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd29, [log_softmax_param_0];
	ld.param.u64 	%rd30, [log_softmax_param_1];
	ld.param.u32 	%r31, [log_softmax_param_2];
	ld.param.u32 	%r30, [log_softmax_param_3];
	cvta.to.global.u64 	%rd1, %rd29;
	cvta.to.global.u64 	%rd2, %rd30;
	mov.u32 	%r32, %nctaid.x;
	mov.u32 	%r33, %ctaid.y;
	mov.u32 	%r34, %ctaid.x;
	mad.lo.s32 	%r35, %r33, %r32, %r34;
	mov.u32 	%r36, %ntid.x;
	mov.u32 	%r37, %tid.x;
	mad.lo.s32 	%r1, %r35, %r36, %r37;
	setp.ge.s32 	%p1, %r1, %r31;
	@%p1 bra 	$L__BB3_32;

	setp.lt.s32 	%p2, %r30, 1;
	mov.f32 	%f164, 0fFF7FFFFF;
	@%p2 bra 	$L__BB3_8;

	add.s32 	%r39, %r30, -1;
	and.b32  	%r69, %r30, 3;
	setp.lt.u32 	%p3, %r39, 3;
	mov.f32 	%f164, 0fFF7FFFFF;
	mov.u32 	%r68, 0;
	@%p3 bra 	$L__BB3_5;

	sub.s32 	%r67, %r30, %r69;
	mul.lo.s32 	%r41, %r30, %r1;
	mul.wide.s32 	%rd31, %r41, 4;
	add.s64 	%rd32, %rd1, %rd31;
	add.s64 	%rd40, %rd32, 8;

$L__BB3_4:
	ld.global.f32 	%f36, [%rd40+-8];
	setp.le.f32 	%p4, %f164, %f36;
	selp.f32 	%f37, %f36, %f164, %p4;
	ld.global.f32 	%f38, [%rd40+-4];
	setp.le.f32 	%p5, %f37, %f38;
	selp.f32 	%f39, %f38, %f37, %p5;
	ld.global.f32 	%f40, [%rd40];
	setp.le.f32 	%p6, %f39, %f40;
	selp.f32 	%f41, %f40, %f39, %p6;
	ld.global.f32 	%f42, [%rd40+4];
	setp.le.f32 	%p7, %f41, %f42;
	selp.f32 	%f164, %f42, %f41, %p7;
	add.s32 	%r68, %r68, 4;
	add.s64 	%rd40, %rd40, 16;
	add.s32 	%r67, %r67, -4;
	setp.ne.s32 	%p8, %r67, 0;
	@%p8 bra 	$L__BB3_4;

$L__BB3_5:
	setp.eq.s32 	%p9, %r69, 0;
	@%p9 bra 	$L__BB3_8;

	mad.lo.s32 	%r42, %r30, %r1, %r68;
	mul.wide.s32 	%rd33, %r42, 4;
	add.s64 	%rd41, %rd1, %rd33;

$L__BB3_7:
	.pragma "nounroll";
	ld.global.f32 	%f43, [%rd41];
	setp.le.f32 	%p10, %f164, %f43;
	selp.f32 	%f164, %f43, %f164, %p10;
	add.s64 	%rd41, %rd41, 4;
	add.s32 	%r69, %r69, -1;
	setp.ne.s32 	%p11, %r69, 0;
	@%p11 bra 	$L__BB3_7;

$L__BB3_8:
	mov.f32 	%f169, 0f00000000;
	@%p2 bra 	$L__BB3_15;

	add.s32 	%r44, %r30, -1;
	and.b32  	%r73, %r30, 3;
	setp.lt.u32 	%p13, %r44, 3;
	mov.f32 	%f169, 0f00000000;
	mov.u32 	%r72, 0;
	@%p13 bra 	$L__BB3_12;

	sub.s32 	%r71, %r30, %r73;
	mul.lo.s32 	%r46, %r30, %r1;
	mul.wide.s32 	%rd34, %r46, 4;
	add.s64 	%rd35, %rd34, 8;
	add.s64 	%rd43, %rd1, %rd35;
	add.s64 	%rd42, %rd2, %rd35;
	mov.f32 	%f50, 0f3F000000;
	mov.f32 	%f51, 0f3BBB989D;

$L__BB3_11:
	ld.global.f32 	%f48, [%rd43+-8];
	sub.f32 	%f49, %f48, %f164;
	fma.rn.f32 	%f52, %f49, %f51, %f50;
	mov.f32 	%f53, 0f3FB8AA3B;
	mov.f32 	%f54, 0f437C0000;
	cvt.sat.f32.f32 	%f55, %f52;
	mov.f32 	%f56, 0f4B400001;
	fma.rm.f32 	%f57, %f55, %f54, %f56;
	add.f32 	%f58, %f57, 0fCB40007F;
	neg.f32 	%f59, %f58;
	fma.rn.f32 	%f60, %f49, %f53, %f59;
	mov.f32 	%f61, 0f32A57060;
	fma.rn.f32 	%f62, %f49, %f61, %f60;
	mov.b32 	%r47, %f57;
	shl.b32 	%r48, %r47, 23;
	mov.b32 	%f63, %r48;
	ex2.approx.ftz.f32 	%f64, %f62;
	fma.rn.f32 	%f65, %f64, %f63, %f169;
	st.global.f32 	[%rd42+-8], %f49;
	ld.global.f32 	%f66, [%rd43+-4];
	sub.f32 	%f67, %f66, %f164;
	fma.rn.f32 	%f68, %f67, %f51, %f50;
	cvt.sat.f32.f32 	%f69, %f68;
	fma.rm.f32 	%f70, %f69, %f54, %f56;
	add.f32 	%f71, %f70, 0fCB40007F;
	neg.f32 	%f72, %f71;
	fma.rn.f32 	%f73, %f67, %f53, %f72;
	fma.rn.f32 	%f74, %f67, %f61, %f73;
	mov.b32 	%r49, %f70;
	shl.b32 	%r50, %r49, 23;
	mov.b32 	%f75, %r50;
	ex2.approx.ftz.f32 	%f76, %f74;
	fma.rn.f32 	%f77, %f76, %f75, %f65;
	st.global.f32 	[%rd42+-4], %f67;
	ld.global.f32 	%f78, [%rd43];
	sub.f32 	%f79, %f78, %f164;
	fma.rn.f32 	%f80, %f79, %f51, %f50;
	cvt.sat.f32.f32 	%f81, %f80;
	fma.rm.f32 	%f82, %f81, %f54, %f56;
	add.f32 	%f83, %f82, 0fCB40007F;
	neg.f32 	%f84, %f83;
	fma.rn.f32 	%f85, %f79, %f53, %f84;
	fma.rn.f32 	%f86, %f79, %f61, %f85;
	mov.b32 	%r51, %f82;
	shl.b32 	%r52, %r51, 23;
	mov.b32 	%f87, %r52;
	ex2.approx.ftz.f32 	%f88, %f86;
	fma.rn.f32 	%f89, %f88, %f87, %f77;
	st.global.f32 	[%rd42], %f79;
	ld.global.f32 	%f90, [%rd43+4];
	sub.f32 	%f91, %f90, %f164;
	fma.rn.f32 	%f92, %f91, %f51, %f50;
	cvt.sat.f32.f32 	%f93, %f92;
	fma.rm.f32 	%f94, %f93, %f54, %f56;
	add.f32 	%f95, %f94, 0fCB40007F;
	neg.f32 	%f96, %f95;
	fma.rn.f32 	%f97, %f91, %f53, %f96;
	fma.rn.f32 	%f98, %f91, %f61, %f97;
	mov.b32 	%r53, %f94;
	shl.b32 	%r54, %r53, 23;
	mov.b32 	%f99, %r54;
	ex2.approx.ftz.f32 	%f100, %f98;
	fma.rn.f32 	%f169, %f100, %f99, %f89;
	st.global.f32 	[%rd42+4], %f91;
	add.s32 	%r72, %r72, 4;
	add.s64 	%rd43, %rd43, 16;
	add.s64 	%rd42, %rd42, 16;
	add.s32 	%r71, %r71, -4;
	setp.ne.s32 	%p14, %r71, 0;
	@%p14 bra 	$L__BB3_11;

$L__BB3_12:
	setp.eq.s32 	%p15, %r73, 0;
	@%p15 bra 	$L__BB3_15;

	mad.lo.s32 	%r55, %r30, %r1, %r72;
	mul.wide.s32 	%rd36, %r55, 4;
	add.s64 	%rd45, %rd2, %rd36;
	add.s64 	%rd44, %rd1, %rd36;
	mov.f32 	%f103, 0f3F000000;
	mov.f32 	%f104, 0f3BBB989D;

$L__BB3_14:
	.pragma "nounroll";
	ld.global.f32 	%f101, [%rd44];
	sub.f32 	%f102, %f101, %f164;
	fma.rn.f32 	%f105, %f102, %f104, %f103;
	mov.f32 	%f106, 0f3FB8AA3B;
	mov.f32 	%f107, 0f437C0000;
	cvt.sat.f32.f32 	%f108, %f105;
	mov.f32 	%f109, 0f4B400001;
	fma.rm.f32 	%f110, %f108, %f107, %f109;
	add.f32 	%f111, %f110, 0fCB40007F;
	neg.f32 	%f112, %f111;
	fma.rn.f32 	%f113, %f102, %f106, %f112;
	mov.f32 	%f114, 0f32A57060;
	fma.rn.f32 	%f115, %f102, %f114, %f113;
	mov.b32 	%r56, %f110;
	shl.b32 	%r57, %r56, 23;
	mov.b32 	%f116, %r57;
	ex2.approx.ftz.f32 	%f117, %f115;
	fma.rn.f32 	%f169, %f117, %f116, %f169;
	st.global.f32 	[%rd45], %f102;
	add.s64 	%rd45, %rd45, 4;
	add.s64 	%rd44, %rd44, 4;
	add.s32 	%r73, %r73, -1;
	setp.ne.s32 	%p16, %r73, 0;
	@%p16 bra 	$L__BB3_14;

$L__BB3_15:
	@%p2 bra 	$L__BB3_32;

	setp.lt.f32 	%p18, %f169, 0f00800000;
	mul.f32 	%f118, %f169, 0f4B000000;
	selp.f32 	%f15, %f118, %f169, %p18;
	selp.f32 	%f119, 0fC1B80000, 0f00000000, %p18;
	mov.b32 	%r20, %f15;
	add.s32 	%r59, %r20, -1059760811;
	and.b32  	%r60, %r59, -8388608;
	sub.s32 	%r61, %r20, %r60;
	mov.b32 	%f120, %r61;
	cvt.rn.f32.s32 	%f121, %r60;
	mov.f32 	%f122, 0f34000000;
	fma.rn.f32 	%f123, %f121, %f122, %f119;
	add.f32 	%f124, %f120, 0fBF800000;
	mov.f32 	%f125, 0f3E1039F6;
	mov.f32 	%f126, 0fBE055027;
	fma.rn.f32 	%f127, %f126, %f124, %f125;
	mov.f32 	%f128, 0fBDF8CDCC;
	fma.rn.f32 	%f129, %f127, %f124, %f128;
	mov.f32 	%f130, 0f3E0F2955;
	fma.rn.f32 	%f131, %f129, %f124, %f130;
	mov.f32 	%f132, 0fBE2AD8B9;
	fma.rn.f32 	%f133, %f131, %f124, %f132;
	mov.f32 	%f134, 0f3E4CED0B;
	fma.rn.f32 	%f135, %f133, %f124, %f134;
	mov.f32 	%f136, 0fBE7FFF22;
	fma.rn.f32 	%f137, %f135, %f124, %f136;
	mov.f32 	%f138, 0f3EAAAA78;
	fma.rn.f32 	%f139, %f137, %f124, %f138;
	mov.f32 	%f140, 0fBF000000;
	fma.rn.f32 	%f141, %f139, %f124, %f140;
	mul.f32 	%f142, %f124, %f141;
	fma.rn.f32 	%f143, %f142, %f124, %f124;
	mov.f32 	%f144, 0f3F317218;
	fma.rn.f32 	%f16, %f123, %f144, %f143;
	and.b32  	%r77, %r30, 3;
	add.s32 	%r62, %r30, -1;
	setp.lt.u32 	%p19, %r62, 3;
	mov.u32 	%r76, 0;
	@%p19 bra 	$L__BB3_27;

	sub.s32 	%r75, %r30, %r77;
	mul.lo.s32 	%r64, %r30, %r1;
	mul.wide.s32 	%rd37, %r64, 4;
	add.s64 	%rd38, %rd2, %rd37;
	add.s64 	%rd46, %rd38, 8;
	setp.lt.u32 	%p20, %r20, 2139095040;
	setp.eq.f32 	%p21, %f15, 0f00000000;

$L__BB3_18:
	add.s64 	%rd23, %rd46, -8;
	ld.global.f32 	%f17, [%rd46+-8];
	mov.f32 	%f170, %f16;
	@%p20 bra 	$L__BB3_20;

	mov.f32 	%f145, 0f7F800000;
	fma.rn.f32 	%f170, %f15, %f145, %f145;

$L__BB3_20:
	selp.f32 	%f146, 0fFF800000, %f170, %p21;
	sub.f32 	%f147, %f17, %f146;
	st.global.f32 	[%rd23], %f147;
	ld.global.f32 	%f20, [%rd23+4];
	mov.f32 	%f171, %f16;
	@%p20 bra 	$L__BB3_22;

	mov.f32 	%f148, 0f7F800000;
	fma.rn.f32 	%f171, %f15, %f148, %f148;

$L__BB3_22:
	selp.f32 	%f149, 0fFF800000, %f171, %p21;
	sub.f32 	%f150, %f20, %f149;
	st.global.f32 	[%rd23+4], %f150;
	ld.global.f32 	%f23, [%rd23+8];
	mov.f32 	%f172, %f16;
	@%p20 bra 	$L__BB3_24;

	mov.f32 	%f151, 0f7F800000;
	fma.rn.f32 	%f172, %f15, %f151, %f151;

$L__BB3_24:
	selp.f32 	%f152, 0fFF800000, %f172, %p21;
	sub.f32 	%f153, %f23, %f152;
	st.global.f32 	[%rd23+8], %f153;
	ld.global.f32 	%f26, [%rd23+12];
	mov.f32 	%f173, %f16;
	@%p20 bra 	$L__BB3_26;

	mov.f32 	%f154, 0f7F800000;
	fma.rn.f32 	%f173, %f15, %f154, %f154;

$L__BB3_26:
	selp.f32 	%f155, 0fFF800000, %f173, %p21;
	sub.f32 	%f156, %f26, %f155;
	st.global.f32 	[%rd23+12], %f156;
	add.s32 	%r76, %r76, 4;
	add.s64 	%rd46, %rd46, 16;
	add.s32 	%r75, %r75, -4;
	setp.ne.s32 	%p28, %r75, 0;
	@%p28 bra 	$L__BB3_18;

$L__BB3_27:
	setp.eq.s32 	%p29, %r77, 0;
	@%p29 bra 	$L__BB3_32;

	mad.lo.s32 	%r65, %r30, %r1, %r76;
	mul.wide.s32 	%rd39, %r65, 4;
	add.s64 	%rd47, %rd2, %rd39;
	setp.lt.u32 	%p30, %r20, 2139095040;
	mov.f32 	%f157, 0f7F800000;
	fma.rn.f32 	%f30, %f15, %f157, %f157;
	setp.eq.f32 	%p31, %f15, 0f00000000;

$L__BB3_29:
	.pragma "nounroll";
	ld.global.f32 	%f29, [%rd47];
	mov.f32 	%f174, %f16;
	@%p30 bra 	$L__BB3_31;

	mov.f32 	%f174, %f30;

$L__BB3_31:
	selp.f32 	%f158, 0fFF800000, %f174, %p31;
	sub.f32 	%f159, %f29, %f158;
	st.global.f32 	[%rd47], %f159;
	add.s64 	%rd47, %rd47, 4;
	add.s32 	%r77, %r77, -1;
	setp.ne.s32 	%p32, %r77, 0;
	@%p32 bra 	$L__BB3_29;

$L__BB3_32:
	ret;

}
	// .globl	softmax_back
.visible .entry softmax_back(
	.param .u64 softmax_back_param_0,
	.param .u64 softmax_back_param_1,
	.param .u64 softmax_back_param_2,
	.param .u32 softmax_back_param_3,
	.param .u32 softmax_back_param_4
)
{
	.reg .pred 	%p<12>;
	.reg .f32 	%f<50>;
	.reg .b32 	%r<46>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd34, [softmax_back_param_0];
	ld.param.u64 	%rd35, [softmax_back_param_1];
	ld.param.u64 	%rd36, [softmax_back_param_2];
	ld.param.u32 	%r21, [softmax_back_param_3];
	ld.param.u32 	%r20, [softmax_back_param_4];
	cvta.to.global.u64 	%rd1, %rd36;
	cvta.to.global.u64 	%rd2, %rd34;
	cvta.to.global.u64 	%rd3, %rd35;
	mov.u32 	%r22, %nctaid.x;
	mov.u32 	%r23, %ctaid.y;
	mov.u32 	%r24, %ctaid.x;
	mad.lo.s32 	%r25, %r23, %r22, %r24;
	mov.u32 	%r26, %ntid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r25, %r26, %r27;
	setp.ge.s32 	%p1, %r1, %r21;
	@%p1 bra 	$L__BB4_15;

	setp.lt.s32 	%p2, %r20, 1;
	mov.f32 	%f49, 0f00000000;
	@%p2 bra 	$L__BB4_8;

	add.s32 	%r29, %r20, -1;
	and.b32  	%r41, %r20, 3;
	setp.lt.u32 	%p3, %r29, 3;
	mov.f32 	%f49, 0f00000000;
	mov.u32 	%r40, 0;
	@%p3 bra 	$L__BB4_5;

	sub.s32 	%r39, %r20, %r41;
	mul.lo.s32 	%r31, %r20, %r1;
	mul.wide.s32 	%rd37, %r31, 4;
	add.s64 	%rd38, %rd37, 8;
	add.s64 	%rd44, %rd2, %rd38;
	add.s64 	%rd43, %rd3, %rd38;

$L__BB4_4:
	ld.global.f32 	%f12, [%rd43+-8];
	ld.global.f32 	%f13, [%rd44+-8];
	fma.rn.f32 	%f14, %f13, %f12, %f49;
	ld.global.f32 	%f15, [%rd43+-4];
	ld.global.f32 	%f16, [%rd44+-4];
	fma.rn.f32 	%f17, %f16, %f15, %f14;
	ld.global.f32 	%f18, [%rd43];
	ld.global.f32 	%f19, [%rd44];
	fma.rn.f32 	%f20, %f19, %f18, %f17;
	ld.global.f32 	%f21, [%rd43+4];
	ld.global.f32 	%f22, [%rd44+4];
	fma.rn.f32 	%f49, %f22, %f21, %f20;
	add.s32 	%r40, %r40, 4;
	add.s64 	%rd44, %rd44, 16;
	add.s64 	%rd43, %rd43, 16;
	add.s32 	%r39, %r39, -4;
	setp.ne.s32 	%p4, %r39, 0;
	@%p4 bra 	$L__BB4_4;

$L__BB4_5:
	setp.eq.s32 	%p5, %r41, 0;
	@%p5 bra 	$L__BB4_8;

	mad.lo.s32 	%r32, %r20, %r1, %r40;
	mul.wide.s32 	%rd39, %r32, 4;
	add.s64 	%rd46, %rd3, %rd39;
	add.s64 	%rd45, %rd2, %rd39;

$L__BB4_7:
	.pragma "nounroll";
	ld.global.f32 	%f23, [%rd46];
	ld.global.f32 	%f24, [%rd45];
	fma.rn.f32 	%f49, %f24, %f23, %f49;
	add.s64 	%rd46, %rd46, 4;
	add.s64 	%rd45, %rd45, 4;
	add.s32 	%r41, %r41, -1;
	setp.ne.s32 	%p6, %r41, 0;
	@%p6 bra 	$L__BB4_7;

$L__BB4_8:
	@%p2 bra 	$L__BB4_15;

	add.s32 	%r34, %r20, -1;
	and.b32  	%r45, %r20, 3;
	setp.lt.u32 	%p8, %r34, 3;
	mov.u32 	%r44, 0;
	@%p8 bra 	$L__BB4_12;

	sub.s32 	%r43, %r20, %r45;
	mul.lo.s32 	%r36, %r20, %r1;
	mul.wide.s32 	%rd40, %r36, 4;
	add.s64 	%rd41, %rd40, 8;
	add.s64 	%rd49, %rd2, %rd41;
	add.s64 	%rd48, %rd3, %rd41;
	add.s64 	%rd47, %rd1, %rd41;

$L__BB4_11:
	ld.global.f32 	%f25, [%rd48+-8];
	sub.f32 	%f26, %f25, %f49;
	ld.global.f32 	%f27, [%rd49+-8];
	mul.f32 	%f28, %f26, %f27;
	st.global.f32 	[%rd47+-8], %f28;
	ld.global.f32 	%f29, [%rd48+-4];
	sub.f32 	%f30, %f29, %f49;
	ld.global.f32 	%f31, [%rd49+-4];
	mul.f32 	%f32, %f30, %f31;
	st.global.f32 	[%rd47+-4], %f32;
	ld.global.f32 	%f33, [%rd48];
	sub.f32 	%f34, %f33, %f49;
	ld.global.f32 	%f35, [%rd49];
	mul.f32 	%f36, %f34, %f35;
	st.global.f32 	[%rd47], %f36;
	ld.global.f32 	%f37, [%rd48+4];
	sub.f32 	%f38, %f37, %f49;
	ld.global.f32 	%f39, [%rd49+4];
	mul.f32 	%f40, %f38, %f39;
	st.global.f32 	[%rd47+4], %f40;
	add.s32 	%r44, %r44, 4;
	add.s64 	%rd49, %rd49, 16;
	add.s64 	%rd48, %rd48, 16;
	add.s64 	%rd47, %rd47, 16;
	add.s32 	%r43, %r43, -4;
	setp.ne.s32 	%p9, %r43, 0;
	@%p9 bra 	$L__BB4_11;

$L__BB4_12:
	setp.eq.s32 	%p10, %r45, 0;
	@%p10 bra 	$L__BB4_15;

	mad.lo.s32 	%r37, %r20, %r1, %r44;
	mul.wide.s32 	%rd42, %r37, 4;
	add.s64 	%rd52, %rd1, %rd42;
	add.s64 	%rd51, %rd2, %rd42;
	add.s64 	%rd50, %rd3, %rd42;

$L__BB4_14:
	.pragma "nounroll";
	ld.global.f32 	%f41, [%rd50];
	sub.f32 	%f42, %f41, %f49;
	ld.global.f32 	%f43, [%rd51];
	mul.f32 	%f44, %f42, %f43;
	st.global.f32 	[%rd52], %f44;
	add.s64 	%rd52, %rd52, 4;
	add.s64 	%rd51, %rd51, 4;
	add.s64 	%rd50, %rd50, 4;
	add.s32 	%r45, %r45, -1;
	setp.ne.s32 	%p11, %r45, 0;
	@%p11 bra 	$L__BB4_14;

$L__BB4_15:
	ret;

}
	// .globl	log_softmax_back
.visible .entry log_softmax_back(
	.param .u64 log_softmax_back_param_0,
	.param .u64 log_softmax_back_param_1,
	.param .u64 log_softmax_back_param_2,
	.param .u32 log_softmax_back_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<9>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [log_softmax_back_param_0];
	ld.param.u64 	%rd2, [log_softmax_back_param_1];
	ld.param.u64 	%rd3, [log_softmax_back_param_2];
	ld.param.u32 	%r2, [log_softmax_back_param_3];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.y;
	mad.lo.s32 	%r6, %r5, %r4, %r3;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB5_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f32 	%f1, [%rd8];
	ld.global.f32 	%f2, [%rd6];
	sub.f32 	%f3, %f2, %f1;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f32 	[%rd10], %f3;

$L__BB5_2:
	ret;

}
	// .globl	log_softmax_back2
.visible .entry log_softmax_back2(
	.param .u64 log_softmax_back2_param_0,
	.param .u64 log_softmax_back2_param_1,
	.param .u64 log_softmax_back2_param_2,
	.param .u32 log_softmax_back2_param_3,
	.param .u32 log_softmax_back2_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<6>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [log_softmax_back2_param_0];
	ld.param.u64 	%rd2, [log_softmax_back2_param_1];
	ld.param.u64 	%rd3, [log_softmax_back2_param_2];
	ld.param.u32 	%r3, [log_softmax_back2_param_3];
	ld.param.u32 	%r2, [log_softmax_back2_param_4];
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %nctaid.x;
	mov.u32 	%r6, %ctaid.y;
	mad.lo.s32 	%r7, %r6, %r5, %r4;
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	setp.ge.s32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB6_2;

	cvta.to.global.u64 	%rd4, %rd1;
	mul.wide.s32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd2;
	add.s64 	%rd8, %rd7, %rd5;
	ld.global.f32 	%f1, [%rd8];
	ld.global.f32 	%f2, [%rd6];
	sub.f32 	%f3, %f2, %f1;
	cvt.rn.f32.s32 	%f4, %r2;
	div.rn.f32 	%f5, %f3, %f4;
	cvta.to.global.u64 	%rd9, %rd3;
	add.s64 	%rd10, %rd9, %rd5;
	st.global.f32 	[%rd10], %f5;

$L__BB6_2:
	ret;

}

