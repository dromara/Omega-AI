//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31442593
// Cuda compilation tools, release 11.7, V11.7.99
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_52
.address_size 64

	// .globl	loss

.visible .entry loss(
	.param .u64 loss_param_0,
	.param .u64 loss_param_1,
	.param .u64 loss_param_2,
	.param .u32 loss_param_3,
	.param .u32 loss_param_4,
	.param .f32 loss_param_5
)
{
	.reg .pred 	%p<24>;
	.reg .f32 	%f<257>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<19>;


	ld.param.u64 	%rd8, [loss_param_0];
	ld.param.u64 	%rd9, [loss_param_1];
	ld.param.u64 	%rd7, [loss_param_2];
	ld.param.u32 	%r10, [loss_param_3];
	ld.param.u32 	%r11, [loss_param_4];
	cvta.to.global.u64 	%rd1, %rd9;
	cvta.to.global.u64 	%rd2, %rd8;
	mov.u32 	%r12, %nctaid.x;
	mov.u32 	%r13, %ctaid.y;
	mov.u32 	%r14, %ctaid.x;
	mad.lo.s32 	%r15, %r13, %r12, %r14;
	mov.u32 	%r16, %ntid.x;
	mov.u32 	%r17, %tid.x;
	mad.lo.s32 	%r1, %r15, %r16, %r17;
	setp.ge.s32 	%p1, %r1, %r10;
	@%p1 bra 	$L__BB0_20;

	setp.lt.s32 	%p2, %r11, 1;
	mov.f32 	%f252, 0f00000000;
	@%p2 bra 	$L__BB0_19;

	mul.lo.s32 	%r2, %r1, %r11;
	and.b32  	%r3, %r11, 1;
	setp.eq.s32 	%p3, %r11, 1;
	mov.f32 	%f252, 0f00000000;
	mov.u32 	%r48, 0;
	@%p3 bra 	$L__BB0_13;

	sub.s32 	%r47, %r11, %r3;
	mov.f32 	%f46, 0f34000000;
	mov.f32 	%f49, 0f3E1039F6;

$L__BB0_4:
	add.s32 	%r20, %r48, %r2;
	cvt.s64.s32 	%rd3, %r20;
	mul.wide.s32 	%rd10, %r20, 4;
	add.s64 	%rd4, %rd2, %rd10;
	ld.global.f32 	%f2, [%rd4];
	setp.lt.f32 	%p4, %f2, 0f00800000;
	mul.f32 	%f42, %f2, 0f4B000000;
	selp.f32 	%f3, %f42, %f2, %p4;
	selp.f32 	%f43, 0fC1B80000, 0f00000000, %p4;
	mov.b32 	%r21, %f3;
	add.s32 	%r22, %r21, -1059760811;
	and.b32  	%r23, %r22, -8388608;
	sub.s32 	%r24, %r21, %r23;
	mov.b32 	%f44, %r24;
	cvt.rn.f32.s32 	%f45, %r23;
	fma.rn.f32 	%f47, %f45, %f46, %f43;
	add.f32 	%f48, %f44, 0fBF800000;
	mov.f32 	%f50, 0fBE055027;
	fma.rn.f32 	%f51, %f50, %f48, %f49;
	mov.f32 	%f52, 0fBDF8CDCC;
	fma.rn.f32 	%f53, %f51, %f48, %f52;
	mov.f32 	%f54, 0f3E0F2955;
	fma.rn.f32 	%f55, %f53, %f48, %f54;
	mov.f32 	%f56, 0fBE2AD8B9;
	fma.rn.f32 	%f57, %f55, %f48, %f56;
	mov.f32 	%f58, 0f3E4CED0B;
	fma.rn.f32 	%f59, %f57, %f48, %f58;
	mov.f32 	%f60, 0fBE7FFF22;
	fma.rn.f32 	%f61, %f59, %f48, %f60;
	mov.f32 	%f62, 0f3EAAAA78;
	fma.rn.f32 	%f63, %f61, %f48, %f62;
	mov.f32 	%f64, 0fBF000000;
	fma.rn.f32 	%f65, %f63, %f48, %f64;
	mul.f32 	%f66, %f48, %f65;
	fma.rn.f32 	%f67, %f66, %f48, %f48;
	mov.f32 	%f68, 0f3F317218;
	fma.rn.f32 	%f248, %f47, %f68, %f67;
	setp.lt.u32 	%p5, %r21, 2139095040;
	@%p5 bra 	$L__BB0_6;

	mov.f32 	%f69, 0f7F800000;
	fma.rn.f32 	%f248, %f3, %f69, %f69;

$L__BB0_6:
	setp.eq.f32 	%p6, %f3, 0f00000000;
	selp.f32 	%f7, 0fFF800000, %f248, %p6;
	mov.f32 	%f70, 0f3F800000;
	sub.f32 	%f71, %f70, %f2;
	setp.lt.f32 	%p7, %f71, 0f00800000;
	mul.f32 	%f72, %f71, 0f4B000000;
	selp.f32 	%f8, %f72, %f71, %p7;
	selp.f32 	%f73, 0fC1B80000, 0f00000000, %p7;
	mov.b32 	%r25, %f8;
	add.s32 	%r26, %r25, -1059760811;
	and.b32  	%r27, %r26, -8388608;
	sub.s32 	%r28, %r25, %r27;
	mov.b32 	%f74, %r28;
	cvt.rn.f32.s32 	%f75, %r27;
	fma.rn.f32 	%f77, %f75, %f46, %f73;
	add.f32 	%f78, %f74, 0fBF800000;
	fma.rn.f32 	%f81, %f50, %f78, %f49;
	fma.rn.f32 	%f83, %f81, %f78, %f52;
	fma.rn.f32 	%f85, %f83, %f78, %f54;
	fma.rn.f32 	%f87, %f85, %f78, %f56;
	fma.rn.f32 	%f89, %f87, %f78, %f58;
	fma.rn.f32 	%f91, %f89, %f78, %f60;
	fma.rn.f32 	%f93, %f91, %f78, %f62;
	fma.rn.f32 	%f95, %f93, %f78, %f64;
	mul.f32 	%f96, %f78, %f95;
	fma.rn.f32 	%f97, %f96, %f78, %f78;
	fma.rn.f32 	%f249, %f77, %f68, %f97;
	setp.lt.u32 	%p8, %r25, 2139095040;
	@%p8 bra 	$L__BB0_8;

	mov.f32 	%f99, 0f7F800000;
	fma.rn.f32 	%f249, %f8, %f99, %f99;

$L__BB0_8:
	setp.eq.f32 	%p9, %f8, 0f00000000;
	selp.f32 	%f100, 0fFF800000, %f249, %p9;
	mov.f32 	%f101, 0fC2C80000;
	max.f32 	%f102, %f100, %f101;
	shl.b64 	%rd11, %rd3, 2;
	add.s64 	%rd5, %rd1, %rd11;
	ld.global.f32 	%f103, [%rd5];
	add.f32 	%f104, %f103, 0fBF800000;
	mul.f32 	%f105, %f102, %f104;
	max.f32 	%f106, %f7, %f101;
	mul.f32 	%f107, %f106, %f103;
	sub.f32 	%f108, %f105, %f107;
	add.f32 	%f12, %f252, %f108;
	ld.global.f32 	%f13, [%rd4+4];
	setp.lt.f32 	%p10, %f13, 0f00800000;
	mul.f32 	%f109, %f13, 0f4B000000;
	selp.f32 	%f14, %f109, %f13, %p10;
	selp.f32 	%f110, 0fC1B80000, 0f00000000, %p10;
	mov.b32 	%r29, %f14;
	add.s32 	%r30, %r29, -1059760811;
	and.b32  	%r31, %r30, -8388608;
	sub.s32 	%r32, %r29, %r31;
	mov.b32 	%f111, %r32;
	cvt.rn.f32.s32 	%f112, %r31;
	fma.rn.f32 	%f114, %f112, %f46, %f110;
	add.f32 	%f115, %f111, 0fBF800000;
	fma.rn.f32 	%f118, %f50, %f115, %f49;
	fma.rn.f32 	%f120, %f118, %f115, %f52;
	fma.rn.f32 	%f122, %f120, %f115, %f54;
	fma.rn.f32 	%f124, %f122, %f115, %f56;
	fma.rn.f32 	%f126, %f124, %f115, %f58;
	fma.rn.f32 	%f128, %f126, %f115, %f60;
	fma.rn.f32 	%f130, %f128, %f115, %f62;
	fma.rn.f32 	%f132, %f130, %f115, %f64;
	mul.f32 	%f133, %f115, %f132;
	fma.rn.f32 	%f134, %f133, %f115, %f115;
	fma.rn.f32 	%f250, %f114, %f68, %f134;
	setp.lt.u32 	%p11, %r29, 2139095040;
	@%p11 bra 	$L__BB0_10;

	mov.f32 	%f136, 0f7F800000;
	fma.rn.f32 	%f250, %f14, %f136, %f136;

$L__BB0_10:
	setp.eq.f32 	%p12, %f14, 0f00000000;
	selp.f32 	%f18, 0fFF800000, %f250, %p12;
	sub.f32 	%f138, %f70, %f13;
	setp.lt.f32 	%p13, %f138, 0f00800000;
	mul.f32 	%f139, %f138, 0f4B000000;
	selp.f32 	%f19, %f139, %f138, %p13;
	selp.f32 	%f140, 0fC1B80000, 0f00000000, %p13;
	mov.b32 	%r33, %f19;
	add.s32 	%r34, %r33, -1059760811;
	and.b32  	%r35, %r34, -8388608;
	sub.s32 	%r36, %r33, %r35;
	mov.b32 	%f141, %r36;
	cvt.rn.f32.s32 	%f142, %r35;
	fma.rn.f32 	%f144, %f142, %f46, %f140;
	add.f32 	%f145, %f141, 0fBF800000;
	fma.rn.f32 	%f148, %f50, %f145, %f49;
	fma.rn.f32 	%f150, %f148, %f145, %f52;
	fma.rn.f32 	%f152, %f150, %f145, %f54;
	fma.rn.f32 	%f154, %f152, %f145, %f56;
	fma.rn.f32 	%f156, %f154, %f145, %f58;
	fma.rn.f32 	%f158, %f156, %f145, %f60;
	fma.rn.f32 	%f160, %f158, %f145, %f62;
	fma.rn.f32 	%f162, %f160, %f145, %f64;
	mul.f32 	%f163, %f145, %f162;
	fma.rn.f32 	%f164, %f163, %f145, %f145;
	fma.rn.f32 	%f251, %f144, %f68, %f164;
	setp.lt.u32 	%p14, %r33, 2139095040;
	@%p14 bra 	$L__BB0_12;

	mov.f32 	%f166, 0f7F800000;
	fma.rn.f32 	%f251, %f19, %f166, %f166;

$L__BB0_12:
	setp.eq.f32 	%p15, %f19, 0f00000000;
	selp.f32 	%f167, 0fFF800000, %f251, %p15;
	max.f32 	%f169, %f167, %f101;
	ld.global.f32 	%f170, [%rd5+4];
	add.f32 	%f171, %f170, 0fBF800000;
	mul.f32 	%f172, %f169, %f171;
	max.f32 	%f173, %f18, %f101;
	mul.f32 	%f174, %f173, %f170;
	sub.f32 	%f175, %f172, %f174;
	add.f32 	%f252, %f12, %f175;
	add.s32 	%r48, %r48, 2;
	add.s32 	%r47, %r47, -2;
	setp.ne.s32 	%p16, %r47, 0;
	@%p16 bra 	$L__BB0_4;

$L__BB0_13:
	setp.eq.s32 	%p17, %r3, 0;
	@%p17 bra 	$L__BB0_19;

	add.s32 	%r37, %r48, %r2;
	cvt.s64.s32 	%rd6, %r37;
	mul.wide.s32 	%rd12, %r37, 4;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.f32 	%f26, [%rd13];
	setp.lt.f32 	%p18, %f26, 0f00800000;
	mul.f32 	%f176, %f26, 0f4B000000;
	selp.f32 	%f27, %f176, %f26, %p18;
	selp.f32 	%f177, 0fC1B80000, 0f00000000, %p18;
	mov.b32 	%r38, %f27;
	add.s32 	%r39, %r38, -1059760811;
	and.b32  	%r40, %r39, -8388608;
	sub.s32 	%r41, %r38, %r40;
	mov.b32 	%f178, %r41;
	cvt.rn.f32.s32 	%f179, %r40;
	mov.f32 	%f180, 0f34000000;
	fma.rn.f32 	%f181, %f179, %f180, %f177;
	add.f32 	%f182, %f178, 0fBF800000;
	mov.f32 	%f183, 0f3E1039F6;
	mov.f32 	%f184, 0fBE055027;
	fma.rn.f32 	%f185, %f184, %f182, %f183;
	mov.f32 	%f186, 0fBDF8CDCC;
	fma.rn.f32 	%f187, %f185, %f182, %f186;
	mov.f32 	%f188, 0f3E0F2955;
	fma.rn.f32 	%f189, %f187, %f182, %f188;
	mov.f32 	%f190, 0fBE2AD8B9;
	fma.rn.f32 	%f191, %f189, %f182, %f190;
	mov.f32 	%f192, 0f3E4CED0B;
	fma.rn.f32 	%f193, %f191, %f182, %f192;
	mov.f32 	%f194, 0fBE7FFF22;
	fma.rn.f32 	%f195, %f193, %f182, %f194;
	mov.f32 	%f196, 0f3EAAAA78;
	fma.rn.f32 	%f197, %f195, %f182, %f196;
	mov.f32 	%f198, 0fBF000000;
	fma.rn.f32 	%f199, %f197, %f182, %f198;
	mul.f32 	%f200, %f182, %f199;
	fma.rn.f32 	%f201, %f200, %f182, %f182;
	mov.f32 	%f202, 0f3F317218;
	fma.rn.f32 	%f254, %f181, %f202, %f201;
	setp.lt.u32 	%p19, %r38, 2139095040;
	@%p19 bra 	$L__BB0_16;

	mov.f32 	%f203, 0f7F800000;
	fma.rn.f32 	%f254, %f27, %f203, %f203;

$L__BB0_16:
	setp.eq.f32 	%p20, %f27, 0f00000000;
	selp.f32 	%f31, 0fFF800000, %f254, %p20;
	mov.f32 	%f204, 0f3F800000;
	sub.f32 	%f205, %f204, %f26;
	setp.lt.f32 	%p21, %f205, 0f00800000;
	mul.f32 	%f206, %f205, 0f4B000000;
	selp.f32 	%f32, %f206, %f205, %p21;
	selp.f32 	%f207, 0fC1B80000, 0f00000000, %p21;
	mov.b32 	%r42, %f32;
	add.s32 	%r43, %r42, -1059760811;
	and.b32  	%r44, %r43, -8388608;
	sub.s32 	%r45, %r42, %r44;
	mov.b32 	%f208, %r45;
	cvt.rn.f32.s32 	%f209, %r44;
	fma.rn.f32 	%f211, %f209, %f180, %f207;
	add.f32 	%f212, %f208, 0fBF800000;
	fma.rn.f32 	%f215, %f184, %f212, %f183;
	fma.rn.f32 	%f217, %f215, %f212, %f186;
	fma.rn.f32 	%f219, %f217, %f212, %f188;
	fma.rn.f32 	%f221, %f219, %f212, %f190;
	fma.rn.f32 	%f223, %f221, %f212, %f192;
	fma.rn.f32 	%f225, %f223, %f212, %f194;
	fma.rn.f32 	%f227, %f225, %f212, %f196;
	fma.rn.f32 	%f229, %f227, %f212, %f198;
	mul.f32 	%f230, %f212, %f229;
	fma.rn.f32 	%f231, %f230, %f212, %f212;
	fma.rn.f32 	%f255, %f211, %f202, %f231;
	setp.lt.u32 	%p22, %r42, 2139095040;
	@%p22 bra 	$L__BB0_18;

	mov.f32 	%f233, 0f7F800000;
	fma.rn.f32 	%f255, %f32, %f233, %f233;

$L__BB0_18:
	setp.eq.f32 	%p23, %f32, 0f00000000;
	selp.f32 	%f234, 0fFF800000, %f255, %p23;
	mov.f32 	%f235, 0fC2C80000;
	max.f32 	%f236, %f234, %f235;
	shl.b64 	%rd14, %rd6, 2;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.f32 	%f237, [%rd15];
	add.f32 	%f238, %f237, 0fBF800000;
	mul.f32 	%f239, %f236, %f238;
	max.f32 	%f240, %f31, %f235;
	mul.f32 	%f241, %f240, %f237;
	sub.f32 	%f242, %f239, %f241;
	add.f32 	%f252, %f252, %f242;

$L__BB0_19:
	cvt.rn.f32.s32 	%f243, %r10;
	div.rn.f32 	%f244, %f252, %f243;
	cvt.rn.f32.s32 	%f245, %r11;
	div.rn.f32 	%f246, %f244, %f245;
	cvta.to.global.u64 	%rd16, %rd7;
	mul.wide.s32 	%rd17, %r1, 4;
	add.s64 	%rd18, %rd16, %rd17;
	st.global.f32 	[%rd18], %f246;

$L__BB0_20:
	ret;

}
	// .globl	loss_back
.visible .entry loss_back(
	.param .u64 loss_back_param_0,
	.param .u64 loss_back_param_1,
	.param .u64 loss_back_param_2,
	.param .u32 loss_back_param_3,
	.param .u32 loss_back_param_4
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<40>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<34>;


	ld.param.u64 	%rd22, [loss_back_param_0];
	ld.param.u64 	%rd23, [loss_back_param_1];
	ld.param.u64 	%rd24, [loss_back_param_2];
	ld.param.u32 	%r12, [loss_back_param_3];
	ld.param.u32 	%r11, [loss_back_param_4];
	cvta.to.global.u64 	%rd1, %rd24;
	cvta.to.global.u64 	%rd2, %rd23;
	cvta.to.global.u64 	%rd3, %rd22;
	mov.u32 	%r13, %nctaid.x;
	mov.u32 	%r14, %ctaid.y;
	mov.u32 	%r15, %ctaid.x;
	mad.lo.s32 	%r16, %r14, %r13, %r15;
	mov.u32 	%r17, %ntid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r1, %r16, %r17, %r18;
	setp.ge.s32 	%p1, %r1, %r12;
	setp.lt.s32 	%p2, %r11, 1;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_7;

	add.s32 	%r20, %r11, -1;
	and.b32  	%r27, %r11, 3;
	setp.lt.u32 	%p4, %r20, 3;
	mov.u32 	%r26, 0;
	@%p4 bra 	$L__BB1_4;

	sub.s32 	%r25, %r11, %r27;
	mul.lo.s32 	%r22, %r11, %r1;
	mul.wide.s32 	%rd25, %r22, 4;
	add.s64 	%rd26, %rd25, 8;
	add.s64 	%rd30, %rd2, %rd26;
	add.s64 	%rd29, %rd3, %rd26;
	add.s64 	%rd28, %rd1, %rd26;
	mov.f32 	%f2, 0f3F800000;
	mov.f32 	%f5, 0f2B8CBCCC;

$L__BB1_3:
	ld.global.f32 	%f1, [%rd29+-8];
	sub.f32 	%f3, %f2, %f1;
	mul.f32 	%f4, %f1, %f3;
	max.f32 	%f6, %f4, %f5;
	ld.global.f32 	%f7, [%rd30+-8];
	sub.f32 	%f8, %f1, %f7;
	div.rn.f32 	%f9, %f8, %f6;
	st.global.f32 	[%rd28+-8], %f9;
	ld.global.f32 	%f10, [%rd29+-4];
	sub.f32 	%f11, %f2, %f10;
	mul.f32 	%f12, %f10, %f11;
	max.f32 	%f13, %f12, %f5;
	ld.global.f32 	%f14, [%rd30+-4];
	sub.f32 	%f15, %f10, %f14;
	div.rn.f32 	%f16, %f15, %f13;
	st.global.f32 	[%rd28+-4], %f16;
	ld.global.f32 	%f17, [%rd29];
	sub.f32 	%f18, %f2, %f17;
	mul.f32 	%f19, %f17, %f18;
	max.f32 	%f20, %f19, %f5;
	ld.global.f32 	%f21, [%rd30];
	sub.f32 	%f22, %f17, %f21;
	div.rn.f32 	%f23, %f22, %f20;
	st.global.f32 	[%rd28], %f23;
	ld.global.f32 	%f24, [%rd29+4];
	sub.f32 	%f25, %f2, %f24;
	mul.f32 	%f26, %f24, %f25;
	max.f32 	%f27, %f26, %f5;
	ld.global.f32 	%f28, [%rd30+4];
	sub.f32 	%f29, %f24, %f28;
	div.rn.f32 	%f30, %f29, %f27;
	st.global.f32 	[%rd28+4], %f30;
	add.s32 	%r26, %r26, 4;
	add.s64 	%rd30, %rd30, 16;
	add.s64 	%rd29, %rd29, 16;
	add.s64 	%rd28, %rd28, 16;
	add.s32 	%r25, %r25, -4;
	setp.ne.s32 	%p5, %r25, 0;
	@%p5 bra 	$L__BB1_3;

$L__BB1_4:
	setp.eq.s32 	%p6, %r27, 0;
	@%p6 bra 	$L__BB1_7;

	mad.lo.s32 	%r23, %r11, %r1, %r26;
	mul.wide.s32 	%rd27, %r23, 4;
	add.s64 	%rd33, %rd1, %rd27;
	add.s64 	%rd32, %rd2, %rd27;
	add.s64 	%rd31, %rd3, %rd27;
	mov.f32 	%f32, 0f3F800000;
	mov.f32 	%f35, 0f2B8CBCCC;

$L__BB1_6:
	.pragma "nounroll";
	ld.global.f32 	%f31, [%rd31];
	sub.f32 	%f33, %f32, %f31;
	mul.f32 	%f34, %f31, %f33;
	max.f32 	%f36, %f34, %f35;
	ld.global.f32 	%f37, [%rd32];
	sub.f32 	%f38, %f31, %f37;
	div.rn.f32 	%f39, %f38, %f36;
	st.global.f32 	[%rd33], %f39;
	add.s64 	%rd33, %rd33, 4;
	add.s64 	%rd32, %rd32, 4;
	add.s64 	%rd31, %rd31, 4;
	add.s32 	%r27, %r27, -1;
	setp.ne.s32 	%p7, %r27, 0;
	@%p7 bra 	$L__BB1_6;

$L__BB1_7:
	ret;

}

